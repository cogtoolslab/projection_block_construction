{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic analysis of different block libraries\n",
    "Purpose of this notebook is to compute a number of different measures that allow us to assess different block libraries and the towers that get generated for them.\n",
    "\n",
    "This can be seen a an attempt of providing algorithm-independent measures of tower complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up imports\n",
    "import os\n",
    "import sys\n",
    "__file__ = os.getcwd()\n",
    "proj_dir =  os.path.dirname(os.path.realpath(__file__))\n",
    "sys.path.append(proj_dir)\n",
    "utils_dir = os.path.join(proj_dir,'utils')\n",
    "sys.path.append(utils_dir)\n",
    "analysis_dir = os.path.join(proj_dir,'analysis')\n",
    "analysis_utils_dir = os.path.join(analysis_dir,'utils')\n",
    "sys.path.append(analysis_utils_dir)\n",
    "agent_dir = os.path.join(proj_dir,'model')\n",
    "sys.path.append(agent_dir)\n",
    "agent_util_dir = os.path.join(agent_dir,'utils')\n",
    "sys.path.append(agent_util_dir)\n",
    "experiments_dir = os.path.join(proj_dir,'experiments')\n",
    "sys.path.append(experiments_dir)\n",
    "df_dir = os.path.join(proj_dir,'results/dataframes')\n",
    "stim_dir = os.path.join(proj_dir,'stimuli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import utils.blockworld_library as bl\n",
    "import utils.blockworld as bw\n",
    "from utils.blockworld import *\n",
    "import stimuli.tower_generator as tower_generator\n",
    "\n",
    "from model.Random_Agent import Random_Agent\n",
    "from model.stochastic_tower_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create sets of worlds\n",
    "sets = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just use a random agent here\n",
    "agent = Random_Agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in towers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in towers for bl_nonoverlapping_simple\n",
    "set_ = 'bl_nonoverlapping_simple'\n",
    "PATH_TO_TOWERS = os.path.join(\n",
    "    stim_dir, 'generated_towers_bl_nonoverlapping_simple.pkl')\n",
    "# load towers\n",
    "with open(PATH_TO_TOWERS, 'rb') as f:\n",
    "    towers = pickle.load(f)\n",
    "for i in range(len(towers)):\n",
    "    towers[i]['name'] = str(i)\n",
    "towers = {t['name']: t['bitmap'] for t in towers}\n",
    "worlds = {name: bw.Blockworld(silhouette=silhouette, block_library=bl.bl_nonoverlapping_simple,\n",
    "                              legal_action_space=True, physics=True) for name, silhouette in towers.items()}\n",
    "sets[set_] = worlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in towers for bl_silhouette2_default\n",
    "set_ = 'bl_silhouette2_default'\n",
    "worlds = {'int_struct_'+str(i): bw.Blockworld(silhouette=bl.load_interesting_structure(\n",
    "    i), block_library=bl.bl_silhouette2_default, legal_action_space=True, physics=True) for i in range(1,16+1)}\n",
    "sets[set_] = worlds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OR** alternatively create the towers from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOWERS = 128\n",
    "block_libraries = {\"bl_nonoverlapping_simple\": bl.bl_nonoverlapping_simple, \"bl_nonoverlapping_med\": bl.bl_nonoverlapping_med, \"bl_silhouette2_default\": bl.bl_silhouette2_default}\n",
    "\n",
    "Tower_Generator= tower_generator.TowerGenerator(8, 8,\n",
    "                                   block_library=bl.bl_nonoverlapping_simple,\n",
    "                                   padding=(2, 0),\n",
    "                                   num_blocks=6,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = {}\n",
    "\n",
    "for set_,block_library in block_libraries.items():\n",
    "    # create a number of random towers\n",
    "    sets[set_] = {}\n",
    "    for i in tqdm(range(NUM_TOWERS)):\n",
    "        tower = Tower_Generator.generate()\n",
    "        world = bw.Blockworld(silhouette=tower['bitmap'], block_library=block_library,)\n",
    "        sets[set_][set_+\"_\"+str(i)] = world\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4092"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run it. This can be slow, and jupyter notebook can be time out. Therefore, we'll pickle the inputs, run it offline and then load the result back in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = prep_for_offline_running(sets, agent, N)\n",
    "print(\"\\n Run `python model/stochastic_tower_analysis.py {}` from the repo directory to run the analysis\".format(location.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the output back in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(location)\n",
    "print(\"Read in dataframe with {} rows\".format(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can run it in the notebook and hope that it's fast enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['set', 'tower', 'outcome_ratio', 'avg_branching_factor', 'branching_factors', 'outcomes'])\n",
    "\n",
    "# run the analysis\n",
    "for set_ in sets:\n",
    "    worlds = sets[set_]\n",
    "    for i, world_name in enumerate(worlds.keys()):\n",
    "        print('Set {} -> Analyzing world {} of {}: {}'.format(set_, i, len(worlds), world_name))\n",
    "        world = worlds[world_name]\n",
    "        outcome_ratio, total_branching_factor, branching_factors, outcomes = analyze_single_tower(world, agent, n = N)\n",
    "        # save the results\n",
    "        df = df.append({'set': set_, 'tower': world_name, 'outcome_ratio': outcome_ratio, 'avg_branching_factor': total_branching_factor, 'branching_factors': branching_factors, 'outcomes': outcomes}, ignore_index=True)\n",
    "        clear_output()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many random paths end in success?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.groupby('set').mean()['outcome_ratio'])\n",
    "# make barplot with error bars\n",
    "df.groupby('set').mean()['outcome_ratio'].plot(\n",
    "    kind='bar', yerr=df.groupby('set')['outcome_ratio'].agg(scipy.stats.sem), title='Ratio of winning leaf nodes to all leaf nodes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the average branching factor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.groupby('set').mean()['avg_branching_factor'])\n",
    "# make barplot with errorbars\n",
    "df.groupby('set').mean()['avg_branching_factor'].plot(\n",
    "    kind='bar', yerr=df.groupby('set')['avg_branching_factor'].agg(scipy.stats.sem), title='Mean branching factor')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the average branching factor split up over depth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depth_branching_factor(depth_dict, depth):\n",
    "    assert type(depth_dict) == dict\n",
    "    if depth in depth_dict:\n",
    "        return np.mean(depth_dict[depth])\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's extract the branching factors according to agent and depth\n",
    "set_depth_bfs = {}\n",
    "for set in df['set'].unique():\n",
    "    bfs = {}\n",
    "    _df = df[df['set'] == set]\n",
    "    for i in range(10): # set a reasonable max depth number here\n",
    "        # get the average branching factor for each depth\n",
    "        factors = [get_depth_branching_factor(depth_dict, i) for depth_dict in _df['branching_factors']]\n",
    "        bfs[i] = np.nanmean(factors)\n",
    "    set_depth_bfs[set] = bfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot out the branching factors\n",
    "for set in set_depth_bfs:\n",
    "    plt.plot(set_depth_bfs[set].keys(), set_depth_bfs[set].values(), label=set)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Depth')\n",
    "    plt.ylabel('Branching factor')\n",
    "    plt.title('Branching factor by depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the depth of the random paths?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_depth(outcomes):\n",
    "    return np.mean([o[1] for o in outcomes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add mean depth to df\n",
    "df['mean_depth'] = df['outcomes'].apply(get_mean_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.groupby('set').mean()['mean_depth'])\n",
    "# make barplot with errorbars\n",
    "df.groupby('set').mean()['mean_depth'].plot(\n",
    "    kind='bar', yerr=df.groupby('set')['mean_depth'].agg(scipy.stats.sem), title='Mean depth of leaf nodes')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8a0db0c320a248546b74be3a9327a6b1846905be2e5b5893711db7bb0ee00ed"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('scoping')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
