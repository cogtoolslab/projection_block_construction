{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block construction agent plots from experiment runner dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and worlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T08:38:04.605251Z",
     "start_time": "2020-07-11T08:38:04.235586Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T08:38:04.620782Z",
     "start_time": "2020-07-11T08:38:04.607726Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T08:38:05.646624Z",
     "start_time": "2020-07-11T08:38:05.632740Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#initializing worlds (used for scoring re a certain silhuoette)\n",
    "silhouettes = {i : bl.load_interesting_structure(i) for i in [14,15,5,8,12,1]}\n",
    "worlds_silhouettes = {'int_struct_'+str(i) : bw.Blockworld(silhouette=s,block_library=bl.bl_silhouette2_default) for i,s in silhouettes.items()}\n",
    "worlds_small = {\n",
    "    'stonehenge_6_4' : bw.Blockworld(silhouette=bl.stonehenge_6_4,block_library=bl.bl_stonehenge_6_4),\n",
    "    'stonehenge_3_3' : bw.Blockworld(silhouette=bl.stonehenge_3_3,block_library=bl.bl_stonehenge_3_3),\n",
    "    'block' : bw.Blockworld(silhouette=bl.block,block_library=bl.bl_stonehenge_3_3),\n",
    "    'T' : bw.Blockworld(silhouette=bl.T,block_library=bl.bl_stonehenge_6_4),\n",
    "    'side_by_side' : bw.Blockworld(silhouette=bl.side_by_side,block_library=bl.bl_stonehenge_6_4),\n",
    "}\n",
    "bw_worlds = {**worlds_silhouettes,**worlds_small}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the dataframes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This expects the .pkls in `projection_block_construction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T08:38:23.408617Z",
     "start_time": "2020-07-11T08:38:23.406037Z"
    }
   },
   "outputs": [],
   "source": [
    "dfs = ['../breadth_to_3.pkl',\n",
    "       '../breadth_4.pkl',\n",
    "       '../MCTS.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = ['breadth_to_4_sum.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = ['beam_search.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = ['search_test.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T08:47:18.277305Z",
     "start_time": "2020-07-11T08:47:15.386871Z"
    }
   },
   "outputs": [],
   "source": [
    "#load all experiments as one dataframe\n",
    "df = pd.concat([pd.read_pickle(l) for l in dfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T08:47:50.928290Z",
     "start_time": "2020-07-11T08:47:50.608334Z"
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = df.iloc[1]['run'] #for testing purposes look into a single run\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T13:29:16.681697Z",
     "start_time": "2020-06-23T13:26:01.677658Z"
    }
   },
   "outputs": [],
   "source": [
    "#CAREFUL\n",
    "#view entire dataframe\n",
    "#uncomment to do that\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T08:48:13.217094Z",
     "start_time": "2020-07-11T08:48:13.211134Z"
    }
   },
   "outputs": [],
   "source": [
    "agents = df['agent'].unique()\n",
    "worlds = df['world'].unique()\n",
    "worlds_index = list(set([w.split('|')[0] for w in worlds]))\n",
    "#üêò\n",
    "elephant = 'int_struct_15'\n",
    "stonehenge = 'stonehenge_6_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T08:48:16.815105Z",
     "start_time": "2020-07-11T08:48:16.811347Z"
    }
   },
   "outputs": [],
   "source": [
    "agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T08:48:21.255373Z",
     "start_time": "2020-07-11T08:48:21.251768Z"
    }
   },
   "outputs": [],
   "source": [
    "worlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T11:14:34.285738Z",
     "start_time": "2020-06-24T11:14:34.280153Z"
    }
   },
   "outputs": [],
   "source": [
    "worlds_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-28T19:59:15.650145Z",
     "iopub.status.busy": "2020-07-28T19:59:15.649935Z",
     "iopub.status.idle": "2020-07-28T19:59:15.677999Z",
     "shell.execute_reply": "2020-07-28T19:59:15.676457Z",
     "shell.execute_reply.started": "2020-07-28T19:59:15.650124Z"
    }
   },
   "source": [
    "**Possible measures**\n",
    "Pass a selection of the table to specify.\n",
    "\n",
    "* mean_win(table)\n",
    "* mean_failure_reason(table,reason)\n",
    "* avg_steps_to_end(table)\n",
    "* mean_score(table,scoring_function)\n",
    "* mean_peak_score(table,scoring_function)\n",
    "* mean_avg_area_under_curve(table,scoring_function)\n",
    "* mean_avg_area_under_curve_to_peakF1(table,scoring_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = df['agent'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_win\n",
    "scores = [mean_win(df[df['agent']==a]) for a in agents]    \n",
    "plt.bar(np.arange(len(scores)),scores,align='center',label=agents)\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"Proportion perfect\")\n",
    "plt.title(\"Perfect reconstruction\")\n",
    "# plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_failure_reason\n",
    "#Full\n",
    "scores = [mean_failure_reason(df[df['agent']==a],\"Full\") for a in agents]    \n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',label=\"Full\",width=0.15)\n",
    "#Unstable\n",
    "scores = [mean_failure_reason(df[df['agent']==a],\"Unstable\") for a in agents]    \n",
    "plt.bar(np.arange(len(scores))+.15,scores,align='center',label=\"Unstable\",color='green',width=0.15)\n",
    "#Outside\n",
    "scores = [mean_failure_reason(df[df['agent']==a],\"Outside\") for a in agents]    \n",
    "plt.bar(np.arange(len(scores))+.3,scores,align='center',label=\"Outside\",color='orange',width=0.15)\n",
    "#Holes\n",
    "scores = [mean_failure_reason(df[df['agent']==a],\"Holes\") for a in agents]    \n",
    "plt.bar(np.arange(len(scores))+.45,scores,align='center',label=\"Holes\",color='red',width=0.15)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Reasons for failure\")\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä avg_steps_to_end\n",
    "#all\n",
    "results = [avg_steps_to_end(df[df['agent']==a]) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [avg_steps_to_end(df[(df['agent']==a) & (df['outcome'] == 'Win')]) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [avg_steps_to_end(df[(df['agent']==a) & (df['outcome'] == 'Fail')]) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Average steps\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Average steps to end of run\")\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_score\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_score(df[df['agent']==a],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_score(df[(df['agent']==a) & (df['outcome'] == 'Win')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_score(df[(df['agent']==a) & (df['outcome'] == 'Fail')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean score\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_peak_score\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_peak_score(df[df['agent']==a],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_peak_score(df[(df['agent']==a) & (df['outcome'] == 'Win')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_peak_score(df[(df['agent']==a) & (df['outcome'] == 'Fail')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean peak score\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean peak score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_avg_area_under_curve\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_avg_area_under_curve(df[df['agent']==a],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_avg_area_under_curve(df[(df['agent']==a) & (df['outcome'] == 'Win')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_avg_area_under_curve(df[(df['agent']==a) & (df['outcome'] == 'Fail')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean average area under curve\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean average area under curve per step: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_avg_area_under_curve_to_peakF1\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[df['agent']==a],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[(df['agent']==a) & (df['outcome'] == 'Win')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[(df['agent']==a) & (df['outcome'] == 'Fail')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean average area under curve at peak F1\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean average area under curve per step at peak F1 score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T08:48:41.479807Z",
     "start_time": "2020-07-11T08:48:41.423434Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#wins over agent\n",
    "#output can be pasted into numbers with space as seperator\n",
    "for agent in agents:\n",
    "    wins = 0\n",
    "    total = 0\n",
    "    for o in df[df['agent']==agent]['outcome']:\n",
    "        if o == 'Win':\n",
    "            wins+=1\n",
    "        total += 1\n",
    "    print(wins,'/',total,str(round(100*wins/total,2))+'%',agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average number of steps per agent for failure and success\n",
    "for agent in agents:\n",
    "    win_lengths = []\n",
    "    failure_lengths = []\n",
    "    for i,row in df[df['agent']==agent].iterrows():\n",
    "        num_steps = len(get_blockmaps(row['run'])) # get number of steps\n",
    "        if row['outcome'] == 'Win':\n",
    "            win_lengths.append(num_steps)\n",
    "        if row['outcome'] == 'Fail':\n",
    "            failure_lengths.append(num_steps)\n",
    "    print(agent)\n",
    "    print(len(win_lengths),\"wins with avg length\",sum(win_lengths)/len(win_lengths))\n",
    "    print(len(failure_lengths),\"wins with avg length\",sum(failure_lengths)/len(failure_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#failure reasons per agent\n",
    "for agent in agents:\n",
    "    failure_reasons = {}\n",
    "    for run in df[df['agent'] == agent]['run']:\n",
    "        status, reason = get_final_status(run)\n",
    "        if reason in failure_reasons.keys():\n",
    "            failure_reasons[reason] += 1\n",
    "        else:\n",
    "            failure_reasons[reason] = 1\n",
    "    print(agent,'\\n',failure_reasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T09:51:44.185400Z",
     "start_time": "2020-07-11T09:50:33.664045Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot F1 over time for agent\n",
    "for agent in agents:\n",
    "    plt.clf() #clear the plot\n",
    "    for run in df[df['agent']==agent]['run']:\n",
    "        plt.plot(run['F1 score'].to_list(),linewidth=0.3)\n",
    "    plt.title(agent)\n",
    "    plt.xlim([0,20])\n",
    "    plt.ylim([0,1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T09:56:01.966692Z",
     "start_time": "2020-07-11T09:54:48.318673Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot blocksize over time for agent\n",
    "for agent in agents:\n",
    "    plt.clf() #clear the plot\n",
    "    for run in df[df['agent']==agent]['run']:\n",
    "        blocks_obj = run[run.notnull()['chosen action']]['chosen action'].to_list()\n",
    "        size = [float(a)*float(b) for a,b in [b[0][0][1:-1].split('x') for b in blocks_obj]]\n",
    "        plt.plot(size,linewidth=0.3)\n",
    "    plt.title(agent)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T09:56:01.966692Z",
     "start_time": "2020-07-11T09:54:48.318673Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot avg blocksize over time for agent\n",
    "for agent in agents:\n",
    "    plt.clf() #clear the plot\n",
    "    for run in df[df['agent']==agent]['run']:\n",
    "        blocks_obj = run[run.notnull()['chosen action']]['chosen action'].to_list()\n",
    "        size = [float(a)*float(b) for a,b in [b[0][0][1:-1].split('x') for b in blocks_obj]]\n",
    "        plt.plot(size,linewidth=0.3)\n",
    "    plt.title(\"Average blocksize for \"+agent)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per world\n",
    "Makes more sense to selectively run worlds in the section further below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worlds = df['world'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-29T09:35:50.461450Z",
     "iopub.status.busy": "2020-07-29T09:35:50.461237Z",
     "iopub.status.idle": "2020-07-29T09:35:50.464486Z",
     "shell.execute_reply": "2020-07-29T09:35:50.463453Z",
     "shell.execute_reply.started": "2020-07-29T09:35:50.461428Z"
    }
   },
   "source": [
    "### Bar graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_win\n",
    "scores = [mean_win(df[df['world']==w]) for w in worlds]    \n",
    "plt.bar(np.arange(len(scores)),scores,align='center')\n",
    "plt.xticks(np.arange(len(scores)),worlds,rotation=45,ha='right')\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"Proportion perfect\")\n",
    "plt.title(\"Perfect reconstruction\")\n",
    "# plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_failure_reason\n",
    "#Full\n",
    "scores = [mean_failure_reason(df[df['world']==w],\"Full\") for w in worlds]    \n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',label=\"Full\",width=0.15)\n",
    "#Unstable\n",
    "scores = [mean_failure_reason(df[df['world']==w],\"Unstable\") for w in worlds]    \n",
    "plt.bar(np.arange(len(scores))+.15,scores,align='center',label=\"Unstable\",color='green',width=0.15)\n",
    "#Outside\n",
    "scores = [mean_failure_reason(df[df['world']==w],\"Outside\") for w in worlds]    \n",
    "plt.bar(np.arange(len(scores))+.3,scores,align='center',label=\"Outside\",color='orange',width=0.15)\n",
    "#Holes\n",
    "scores = [mean_failure_reason(df[df['world']==w],\"Holes\") for w in worlds]    \n",
    "plt.bar(np.arange(len(scores))+.45,scores,align='center',label=\"Holes\",color='red',width=0.15)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Reasons for failure\")\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä avg_steps_to_end\n",
    "#all\n",
    "results = [avg_steps_to_end(df[df['world']==w]) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [avg_steps_to_end(df[(df['world']==w) & (df['outcome'] == 'Win')]) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [avg_steps_to_end(df[(df['world']==w) & (df['outcome'] == 'Fail')]) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Average steps\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Average steps to end of run\")\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_score\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_score(df[df['world']==w],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_score(df[(df['world']==w) & (df['outcome'] == 'Win')],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_score(df[(df['world']==w) & (df['outcome'] == 'Fail')],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean score\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_peak_score\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_peak_score(df[df['world']==w],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_peak_score(df[(df['world']==w) & (df['outcome'] == 'Win')],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_peak_score(df[(df['world']==w) & (df['outcome'] == 'Fail')],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean peak score\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean peak score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_avg_area_under_curve\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_avg_area_under_curve(df[df['world']==w],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_avg_area_under_curve(df[(df['world']==w) & (df['outcome'] == 'Win')],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_avg_area_under_curve(df[(df['world']==w) & (df['outcome'] == 'Fail')],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean average area under curve\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean average area under curve per step: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_avg_area_under_curve_to_peakF1\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[df['world']==w],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[(df['world']==w) & (df['outcome'] == 'Win')],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[(df['world']==w) & (df['outcome'] == 'Fail')],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean average area under curve at peak F1\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean average area under curve per step at peak F1 score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T09:29:57.306706Z",
     "start_time": "2020-07-11T09:29:56.830838Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#wins over world\n",
    "for world in worlds_index:\n",
    "    wins = 0\n",
    "    total = 0\n",
    "    for o in df[df['world'].str.contains(world)]['outcome']:\n",
    "        if o == 'Win':\n",
    "            wins+=1\n",
    "        total += 1\n",
    "    print(wins,'/',total,str(round(100*wins/total,2))+'%',world)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-29T11:06:44.822756Z",
     "iopub.status.busy": "2020-07-29T11:06:44.822545Z",
     "iopub.status.idle": "2020-07-29T11:06:44.825629Z",
     "shell.execute_reply": "2020-07-29T11:06:44.824628Z",
     "shell.execute_reply.started": "2020-07-29T11:06:44.822735Z"
    }
   },
   "source": [
    "### Plots & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T15:03:35.753580Z",
     "start_time": "2020-06-23T15:03:29.925935Z"
    }
   },
   "outputs": [],
   "source": [
    "#images of worlds\n",
    "for i,world in enumerate(bw_worlds.values()):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.subplot(3,4,i+1)\n",
    "    plt.imshow(world.silhouette)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T22:43:31.682478Z",
     "start_time": "2020-06-08T22:29:10.228756Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CAUTION, lots of data\n",
    "#plot all blockmaps\n",
    "for agent in agents:\n",
    "    plt.clf() #clear the plot\n",
    "    for run in df[df['agent']==agent]['run']:\n",
    "        bm_obj = run[run.notnull()['blockmap']]['blockmap'].tail(1)\n",
    "        blockmap = np.array(bm_obj.to_list())[0,0,::] #convert object back to np and take the wrappers off\n",
    "        plt.pcolormesh(blockmap[::-1], cmap='hot_r',vmin=0)\n",
    "        plt.title(agent)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T15:03:06.934620Z",
     "start_time": "2020-06-23T15:03:04.984902Z"
    }
   },
   "outputs": [],
   "source": [
    "#win ratio for world\n",
    "for world in worlds_index:\n",
    "    won = 0\n",
    "    total = 0\n",
    "    for index,outcome in df[(df['world'].str.contains(world))][['outcome']].iterrows():\n",
    "        if outcome[0] == 'Win': won += 1\n",
    "        total += 1\n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.imshow(bw_worlds[world.split('|')[0]].silhouette)\n",
    "    plt.show()\n",
    "    print(won,'/',total,'->',(won/total)*100,'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per world & agent\n",
    "Creates **a lot** of bars, better to use chosen world section.\n",
    "\n",
    "More plots in chosen world section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents_worlds = [(a,w) for a in agents for w in worlds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_win\n",
    "scores = [mean_win(df[(df['world']==w) & (df['agent']==a)]) for a,w in agents_worlds]    \n",
    "plt.bar(np.arange(len(scores)),scores,align='center')\n",
    "plt.xticks(np.arange(len(scores)),agents_worlds,rotation=45,ha='right')\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"Proportion perfect\")\n",
    "plt.title(\"Perfect reconstruction\")\n",
    "# plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_failure_reason\n",
    "#Full\n",
    "scores = [mean_failure_reason(df[(df['world']==w) & (df['agent']==a)],\"Full\") for a,w in agents_worlds]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',label=\"Full\",width=0.15)\n",
    "#Unstable\n",
    "scores = [mean_failure_reason(df[(df['world']==w) & (df['agent']==a)],\"Unstable\") for a,w in agents_worlds]\n",
    "plt.bar(np.arange(len(scores))+.15,scores,align='center',label=\"Unstable\",color='green',width=0.15)\n",
    "#Outside\n",
    "scores = [mean_failure_reason(df[(df['world']==w) & (df['agent']==a)],\"Outside\") for a,w in agents_worlds]\n",
    "plt.bar(np.arange(len(scores))+.3,scores,align='center',label=\"Outside\",color='orange',width=0.15)\n",
    "#Holes\n",
    "scores = [mean_failure_reason(df[(df['world']==w) & (df['agent']==a)],\"Holes\") for a,w in agents_worlds]\n",
    "plt.bar(np.arange(len(scores))+.45,scores,align='center',label=\"Holes\",color='red',width=0.15)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents_worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Reasons for failure\")\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä avg_steps_to_end\n",
    "#all\n",
    "results = [avg_steps_to_end(df[(df['world']==w) & (df['agent']==a)]) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [avg_steps_to_end(df[(df['world']==w) & (df['agent']==a)  & (df['outcome'] == 'Win')]) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [avg_steps_to_end(df[(df['world']==w) & (df['agent']==a)  & (df['outcome'] == 'Fail')]) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents_worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Average steps\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Average steps to end of run\")\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_score\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_score(df[(df['world']==w) & (df['agent']==a)],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_score(df[(df['world']==w) & (df['agent']==a)  & (df['outcome'] == 'Win')],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_score(df[(df['world']==w) & (df['agent']==a)  & (df['outcome'] == 'Fail')],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents_worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean score\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_peak_score\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_peak_score(df[(df['world']==w) & (df['agent']==a)],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_peak_score(df[(df['world']==w) & (df['agent']==a)  & (df['outcome'] == 'Win')],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_peak_score(df[(df['world']==w) & (df['agent']==a)  & (df['outcome'] == 'Fail')],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents_worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean peak score\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean peak score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_avg_area_under_curve\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_avg_area_under_curve(df[(df['world']==w) & (df['agent']==a)],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_avg_area_under_curve(df[(df['world']==w) & (df['agent']==a)  & (df['outcome'] == 'Win')],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_avg_area_under_curve(df[(df['world']==w) & (df['agent']==a)  & (df['outcome'] == 'Fail')],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents_worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean average area under curve\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean average area under curve per step: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_avg_area_under_curve_to_peakF1\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[(df['world']==w) & (df['agent']==a)],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[(df['world']==w) & (df['agent']==a)  & (df['outcome'] == 'Win')],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[(df['world']==w) & (df['agent']==a)  & (df['outcome'] == 'Fail')],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents_worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean average area under curve at peak F1\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean average area under curve per step at peak F1 score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T09:58:43.708284Z",
     "start_time": "2020-07-11T09:57:52.621749Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#block size over worlds and agents\n",
    "#crashes, but it's not important anyway\n",
    "for world in worlds_index:\n",
    "    dfw = df[df['world'].str.contains(world)]\n",
    "    for agent in agents:\n",
    "        plt.clf() #clear the plot\n",
    "        for run in dfw[dfw['agent']==agent]['run']:\n",
    "            blocks_obj = run[run.notnull()['chosen action']]['chosen action'].to_list()\n",
    "            size = [float(a)*float(b) for a,b in [b[0][0][1:-1].split('x') for b in blocks_obj]]\n",
    "            plt.plot(size)\n",
    "        plt.title(agent+' on world '+world)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-11T10:01:33.608Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#over worlds and agents: F1 score\n",
    "for world in worlds_index:\n",
    "    dfw = df[df['world'].str.contains(world)]\n",
    "    bw_world = bw_worlds[world.split('|')[0]]\n",
    "    for agent in agents:\n",
    "        plt.clf() #clear the plot\n",
    "        for run in dfw[dfw['agent']==agent]['run']:\n",
    "            blocks_obj = run[run.notnull()['chosen action']]['chosen action'].to_list()\n",
    "            bm_obj = run[run.notnull()['blockmap']]['blockmap'].tail(1)\n",
    "            blockmap = np.array(bm_obj.to_list())[0,0,::] #convert object back to np and take the wrappers off\n",
    "            scores = []\n",
    "            for move in range(np.max(blockmap)): #for every move\n",
    "                _bmm = blockmap * (blockmap <= move)\n",
    "                _state = State(bw_world,_bmm)\n",
    "                score = bw.F1score(_state)\n",
    "                scores.append(score)\n",
    "            plt.plot(scores)\n",
    "        plt.title(agent+' on world '+world)\n",
    "        plt.xlim([0,20])\n",
    "        plt.ylim([0,1])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T23:23:23.748590Z",
     "start_time": "2020-06-08T23:23:23.131345Z"
    }
   },
   "outputs": [],
   "source": [
    "#over worlds and agents: precision score\n",
    "for world in worlds:\n",
    "    dfw = df[df['world']==world]\n",
    "    bw_world = bw_worlds[world]\n",
    "    for agent in agents:\n",
    "        plt.clf() #clear the plot\n",
    "        for run in dfw[dfw['agent']==agent]['run']:\n",
    "            blocks_obj = run[run.notnull()['chosen action']]['chosen action'].to_list()\n",
    "            bm_obj = run[run.notnull()['blockmap']]['blockmap'].tail(1)\n",
    "            blockmap = np.array(bm_obj.to_list())[0,0,::] #convert object back to np and take the wrappers off\n",
    "            for move in range(np.max(blockmap)): #for every move\n",
    "                _bmm = blockmap * (blockmap <= move)\n",
    "                _state = State(bw_worlds[world.split('|')[0]],_bmm)\n",
    "                score = bw.precision(_state)\n",
    "                scores.append(score)\n",
    "            plt.plot(scores)\n",
    "        plt.title(agent+' on world '+world)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T15:03:06.934620Z",
     "start_time": "2020-06-23T15:03:04.984902Z"
    }
   },
   "outputs": [],
   "source": [
    "#win ratio for world & agent\n",
    "for world in worlds_index:\n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.imshow(bw_worlds[world.split('|')[0]].silhouette)\n",
    "    plt.show()\n",
    "    for agent in agents:\n",
    "        won = 0\n",
    "        total = 0\n",
    "        for index,outcome in df[(df['world'].str.contains(world)) & (df['agent'] == agent)][['outcome']].iterrows():\n",
    "            if outcome[0] == 'Win': won += 1\n",
    "            total += 1\n",
    "        print(agent,':',won,'/',total,'->',(won/total)*100,'%')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-11T15:30:51.436900Z",
     "iopub.status.busy": "2020-07-11T15:30:51.436681Z",
     "iopub.status.idle": "2020-07-11T15:30:51.451438Z",
     "shell.execute_reply": "2020-07-11T15:30:51.450205Z",
     "shell.execute_reply.started": "2020-07-11T15:30:51.436879Z"
    }
   },
   "source": [
    "## Per horizon\n",
    "### Plots\n",
    "Generally, it makes more sense to narrow the agents down to only have differences in types between horizon rather than integrate between horizon and then run per agent plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T23:23:48.433436Z",
     "start_time": "2020-06-08T23:23:25.827044Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot F1 over time for horizon\n",
    "for horizon in ['1','2','3']:\n",
    "    plt.clf() #clear the plot\n",
    "    for row in df[df['agent'].str.contains(\"horizon: \"+horizon)][['run','world']].iterrows():\n",
    "        index, row = row\n",
    "        run,world = row\n",
    "        blocks_obj = run[run.notnull()['chosen action']]['chosen action'].to_list()\n",
    "        bm_obj = run[run.notnull()['blockmap']]['blockmap'].tail(1)\n",
    "        blockmap = np.array(bm_obj.to_list())[0,0,::] #convert object back to np and take the wrappers off\n",
    "        scores =[]\n",
    "        for move in range(np.max(blockmap)): #for every move\n",
    "            _bmm = blockmap * (blockmap <= move)\n",
    "            _state = State(bw_worlds[world.split('|')[0]],_bmm)\n",
    "            score = bw.F1score(_state)\n",
    "            scores.append(score)\n",
    "        plt.plot(scores,linewidth=0.1)\n",
    "    plt.title(horizon)\n",
    "    plt.ylabel('F1 score')\n",
    "    plt.xlabel('Step')\n",
    "    plt.xlim(0,32)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T15:03:35.753580Z",
     "start_time": "2020-06-23T15:03:29.925935Z"
    }
   },
   "outputs": [],
   "source": [
    "#images of worlds\n",
    "for i,world in enumerate(bw_worlds.values()):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.subplot(3,4,i+1)\n",
    "    plt.imshow(world.silhouette)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per chosen world\n",
    "For comparisions between agents on a particular world. Most plots make the most sense here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T17:09:15.141655Z",
     "start_time": "2020-06-24T17:09:15.138260Z"
    }
   },
   "outputs": [],
   "source": [
    "# chosen_world = elephant\n",
    "chosen_world = 'stonehenge_6_4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-29T11:38:22.310198Z",
     "iopub.status.busy": "2020-07-29T11:38:22.309938Z",
     "iopub.status.idle": "2020-07-29T11:38:22.313030Z",
     "shell.execute_reply": "2020-07-29T11:38:22.312349Z",
     "shell.execute_reply.started": "2020-07-29T11:38:22.310171Z"
    }
   },
   "source": [
    "### Bar graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_win\n",
    "scores = [mean_win(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)]) for a in agents]    \n",
    "plt.bar(np.arange(len(scores)),scores,align='center')\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"Proportion perfect\")\n",
    "plt.title(\"Perfect reconstruction\")\n",
    "# plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_failure_reason\n",
    "#Full\n",
    "scores = [mean_failure_reason(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)],\"Full\") for a in agents]    \n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',label=\"Full\",width=0.15)\n",
    "#Unstable\n",
    "scores = [mean_failure_reason(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)],\"Unstable\") for a in agents]    \n",
    "plt.bar(np.arange(len(scores))+.15,scores,align='center',label=\"Unstable\",color='green',width=0.15)\n",
    "#Outside\n",
    "scores = [mean_failure_reason(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)],\"Outside\") for a in agents]    \n",
    "plt.bar(np.arange(len(scores))+.3,scores,align='center',label=\"Outside\",color='orange',width=0.15)\n",
    "#Holes\n",
    "scores = [mean_failure_reason(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)],\"Holes\") for a in agents]    \n",
    "plt.bar(np.arange(len(scores))+.45,scores,align='center',label=\"Holes\",color='red',width=0.15)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Reasons for failure\")\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä avg_steps_to_end\n",
    "#all\n",
    "results = [avg_steps_to_end(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)]) for a in agents]\n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [avg_steps_to_end(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)  & (df['outcome'] == 'Win')]) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [avg_steps_to_end(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)  & (df['outcome'] == 'Fail')]) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Average steps\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Average steps to end of run\")\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_score\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_score(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_score(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)  & (df['outcome'] == 'Win')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_score(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)  & (df['outcome'] == 'Fail')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean score\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_peak_score\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_peak_score(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_peak_score(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)  & (df['outcome'] == 'Win')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_peak_score(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)  & (df['outcome'] == 'Fail')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean peak score\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean peak score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_avg_area_under_curve\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_avg_area_under_curve(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_avg_area_under_curve(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)  & (df['outcome'] == 'Win')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_avg_area_under_curve(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)  & (df['outcome'] == 'Fail')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean average area under curve\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean average area under curve per step: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä mean_avg_area_under_curve_to_peakF1\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)  & (df['outcome'] == 'Win')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)  & (df['outcome'] == 'Fail')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean average area under curve at peak F1\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean average area under curve per step at peak F1 score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-29T11:38:33.101620Z",
     "iopub.status.busy": "2020-07-29T11:38:33.101411Z",
     "iopub.status.idle": "2020-07-29T11:38:33.105058Z",
     "shell.execute_reply": "2020-07-29T11:38:33.104091Z",
     "shell.execute_reply.started": "2020-07-29T11:38:33.101598Z"
    }
   },
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average number of steps per agent on chosen world for failure and success\n",
    "for agent in agents:\n",
    "    win_lengths = []\n",
    "    failure_lengths = []\n",
    "    for i,row in df[(df['agent']==agent) & (df['world'].str.contains(chosen_world))].iterrows():\n",
    "        num_steps = len(get_blockmaps(row['run'])) # get number of steps\n",
    "        if row['outcome'] == 'Win':\n",
    "            win_lengths.append(num_steps)\n",
    "        if row['outcome'] == 'Fail':\n",
    "            failure_lengths.append(num_steps)\n",
    "    print(agent)\n",
    "    print(len(win_lengths),\"wins with avg length\",sum(win_lengths)/(len(win_lengths)+0.0001))\n",
    "    print(len(failure_lengths),\"failures with avg length\",sum(failure_lengths)/(len(failure_lengths)+0.0001))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over agents in one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T15:02:22.676359Z",
     "start_time": "2020-06-24T15:02:22.506188Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#wins over agent for chosen world\n",
    "for agent in agents:\n",
    "    wins = 0\n",
    "    total = 0\n",
    "    for o in df[(df['agent']==agent) & (df['world'].str.contains(chosen_world))]['outcome']:\n",
    "        if o == 'Win':\n",
    "            wins+=1\n",
    "        total += 1\n",
    "    print(wins,'/',total,str(round(100*wins/total,2))+'%',agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot all F1 over time for chosen world and over agents colored by success\n",
    "runs = get_BFS_runs(_world_indexes=[chosen_world]) #get runs\n",
    "_agents = runs['agent'].unique() #get agents\n",
    "for _agent in _agents: #plot per agent\n",
    "    a_runs = runs[runs['agent'] == _agent]\n",
    "    for i,row in a_runs.iterrows(): #for each run of the agent\n",
    "        blockmaps = get_blockmaps(row['run']) #get sequence of blockmaps\n",
    "        fin_status,fin_reason = get_final_status(row['run'])\n",
    "        #calculate the score for each blockmap\n",
    "        scores = []\n",
    "        for bm in blockmaps:\n",
    "            #make a State to score\n",
    "            state = State(chosen_world_obj,bm)\n",
    "            score = bw.F1score(state)\n",
    "            scores.append(score)\n",
    "        #plot\n",
    "        plt.plot(scores,linewidth=0.3,c='green' if fin_status == 'Win' else 'red')\n",
    "        plt.xlim(0,xlim)\n",
    "        plt.ylim(0,1)\n",
    "    plt.title('F1 for '+_agent)\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot all F1 over time for chosen world and over agents‚Äîendaligned\n",
    "runs = get_BFS_runs(_world_indexes=[chosen_world]) #get runs\n",
    "_agents = runs['agent'].unique() #get agents\n",
    "for _agent in _agents: #plot per agent\n",
    "    a_runs = runs[runs['agent'] == _agent]\n",
    "    for i,row in a_runs.iterrows(): #for each run of the agent\n",
    "        blockmaps = get_blockmaps(row['run']) #get sequence of blockmaps\n",
    "        fin_status,fin_reason = get_final_status(row['run'])\n",
    "        #calculate the score for each blockmap\n",
    "        scores = []\n",
    "        for bm in blockmaps:\n",
    "            #make a State to score\n",
    "            state = State(chosen_world_obj,bm)\n",
    "            score = bw.F1score(state)\n",
    "            scores.append(score)\n",
    "        #plot\n",
    "        plt.plot(scores[::-1],linewidth=0.3,c='green' if fin_status == 'Win' else 'red')\n",
    "        plt.xlim(xlim,0)\n",
    "        plt.ylim(0,1)\n",
    "    plt.title('F1 for '+_agent)\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot mean F1,std over time for chosen world and over agents in one plot (with continuation)\n",
    "#change scoring function to precision, recall,...\n",
    "runs = get_BFS_runs(_world_indexes=[chosen_world]) #get runs\n",
    "_agents = runs['agent'].unique() #get agents\n",
    "for _agent in _agents: #plot per agent\n",
    "    a_runs = runs[runs['agent'] == _agent]\n",
    "    run_scores = []\n",
    "    for i,row in a_runs.iterrows(): #for each run of the agent\n",
    "        blockmaps = get_blockmaps(row['run']) #get sequence of blockmaps\n",
    "        #calculate the score for each blockmap\n",
    "        scores = []\n",
    "        for bm in blockmaps:\n",
    "            #make a State to score\n",
    "            state = State(chosen_world_obj,bm)\n",
    "            score = bw.F1score(state)\n",
    "            scores.append(score)\n",
    "        #append (pad) score with last value to xlim as a way of handling the early termination of trials\n",
    "        scores = [scores[i] if i < len(scores) else scores[-1] for i in range(xlim+1)]\n",
    "        run_scores.append(scores)\n",
    "    #avg,std\n",
    "    avgs = np.mean(run_scores,axis=0)\n",
    "    stds = np.std(run_scores,axis=0)\n",
    "    #plot\n",
    "#     plt.plot(range(len(avgs)),avgs)\n",
    "    plt.errorbar(range(len(avgs)),avgs,stds,label=_agent)\n",
    "    plt.xlim(0,xlim)\n",
    "    plt.ylim(0,1)\n",
    "plt.title('Mean F1')\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot avg blocksize over time for agent in chosen world\n",
    "#mind that most of the later ones are NaNs!\n",
    "for agent in agents:\n",
    "    sizes_runs = []\n",
    "    for run in df[(df['agent']==agent) & df['world'].str.contains(chosen_world)]['run']:\n",
    "        blocks_obj = run[run.notnull()['chosen action']]['chosen action'].to_list()\n",
    "        sizes_run = [float(a)*float(b) for a,b in [b[0][0][1:-1].split('x') for b in blocks_obj]]\n",
    "        sizes_runs.append(sizes_run)\n",
    "    len_seq = max([len(s) for s in sizes_runs]) #length of the longest sequence\n",
    "    runs_arr = np.full([len(sizes_runs),len_seq],np.nan)\n",
    "    #fill the array\n",
    "    for i,sizes_run in enumerate(sizes_runs):\n",
    "        runs_arr[i,0:len(sizes_run)] = sizes_run\n",
    "    #get stats\n",
    "    means = np.nanmean(runs_arr,axis=0)\n",
    "    stds = np.nanstd(runs_arr,axis=0)\n",
    "    plt.errorbar(range(len(means)),means,stds,label=agent)\n",
    "plt.title(\"Average blocksize\")\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run selectors\n",
    "Helper functions to generate dataframes according to specifications of the agent. \n",
    "- [ ] Move to analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BFS_runs(_sparses = ['False','True'],\n",
    "                 _horizons = ['1','2','3','4','5'],\n",
    "                 _scoring_functions=['random_scoring',\n",
    "                            'silhouette_hole_score','silhouette_score','F1score'],\n",
    "                 _scorings = ['Sum','Average','Random','Final_state'],\n",
    "                 _outcomes = ['Fail','Ongoing','Win'],\n",
    "                 _reasons = None,\n",
    "                 _world_indexes=None):\n",
    "    \"\"\"Returns all rows of the dataframe that fit the list of parameters. \n",
    "    Parameters must be passed as lists.\n",
    "    All reasons are ['None','Full','Holes','Unstable']\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    if _world_indexes is None:\n",
    "        _world_indexes = worlds_index\n",
    "    for world_index in _world_indexes:\n",
    "        dfw = df[df['world'].str.contains(world_index)] #get the lines of the corresponding world\n",
    "        for horizon in _horizons:\n",
    "            for scoring_function in _scoring_functions:\n",
    "                for sparse in _sparses:\n",
    "                    for scoring in _scorings:\n",
    "                        filter = \"type: BFS_Agent scoring: \"+scoring_function+\" horizon: \"+horizon+\" scoring: \"+scoring +\" sparse\\?: \"+sparse\n",
    "                        dfwa = dfw[dfw['agent'].str.contains(filter)]\n",
    "                        for outcome in _outcomes:\n",
    "                            rows.append(dfwa[dfwa['outcome'] == outcome])\n",
    "    dfc = pd.concat(rows)\n",
    "    if _reasons is not None: #if we want to know the reason of failure\n",
    "        reasons = [get_final_status(run)[1] for run in dfc['run']]\n",
    "        filter = [True if reason in _reasons else False for reason in reasons]\n",
    "        dfc = dfc[filter]\n",
    "    return dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT TESTED YET\n",
    "def get_MCTS_runs(_budgets = ['10','100','1000','10000','100000'],\n",
    "                 _outcomes = ['Fail','Ongoing','Win'],\n",
    "                 _reasons = None,\n",
    "                 _world_indexes=None):\n",
    "    \"\"\"Returns all rows of the dataframe that fit the list of parameters. \n",
    "    Parameters must be passed as lists.\n",
    "    All reasons are ['None','Full','Holes','Unstable']\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    if _world_indexes is None:\n",
    "        _world_indexes = worlds_index\n",
    "    for world_index in _world_indexes:\n",
    "        dfw = df[df['world'].str.contains(world_index)] #get the lines of the corresponding world\n",
    "        for budget in _budgets:\n",
    "            filter = \"type: MCTS_Agent horizon: \"+horizon+'\\Z'\n",
    "            dfwa = dfw[dfw['agent'].str.contains(filter)]\n",
    "            for outcome in _outcomes:\n",
    "                rows.append(dfwa[dfwa['outcome'] == outcome])\n",
    "    dfc = pd.concat(rows)\n",
    "    if _reasons is not None: #if we want to know the reason of failure\n",
    "        reasons = [get_final_status(run)[1] for run in dfc['run']]\n",
    "        filter = [True if reason in _reasons else False for reason in reasons]\n",
    "        dfc = dfc[filter]\n",
    "    return dfc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('projection_blocks': conda)",
   "language": "python",
   "name": "python38264bitprojectionblocksconda86e74604eaa74b86af1676acbf4e26f9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "notify_time": "5",
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
