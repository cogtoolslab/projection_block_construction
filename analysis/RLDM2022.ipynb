{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RLDM 2022 figures & analysis\n",
    "\n",
    "This notebook contains analysis files for the RLDM 2022 update to visual scoping.\n",
    "\n",
    "Requires:\n",
    "\n",
    "* `.pkl` generated by `experiment/RLDM_*_experiment.py`\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:26:39.343936Z",
     "iopub.status.busy": "2021-05-09T19:26:39.343598Z",
     "iopub.status.idle": "2021-05-09T19:26:39.354499Z",
     "shell.execute_reply": "2021-05-09T19:26:39.353020Z",
     "shell.execute_reply.started": "2021-05-09T19:26:39.343896Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up imports\n",
    "import os\n",
    "import sys\n",
    "__file__ = os.getcwd()\n",
    "proj_dir =  os.path.dirname(os.path.realpath(__file__))\n",
    "sys.path.append(proj_dir)\n",
    "utils_dir = os.path.join(proj_dir,'utils')\n",
    "sys.path.append(utils_dir)\n",
    "analysis_dir = os.path.join(proj_dir,'analysis')\n",
    "analysis_utils_dir = os.path.join(analysis_dir,'utils')\n",
    "sys.path.append(analysis_utils_dir)\n",
    "agent_dir = os.path.join(proj_dir,'model')\n",
    "sys.path.append(agent_dir)\n",
    "agent_util_dir = os.path.join(agent_dir,'utils')\n",
    "sys.path.append(agent_util_dir)\n",
    "experiments_dir = os.path.join(proj_dir,'experiments')\n",
    "stim_dir = os.path.join(proj_dir,'stimuli')\n",
    "sys.path.append(stim_dir)\n",
    "sys.path.append(experiments_dir)\n",
    "df_dir = os.path.join(proj_dir,'results/dataframes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:26:39.984610Z",
     "iopub.status.busy": "2021-05-09T19:26:39.984317Z",
     "iopub.status.idle": "2021-05-09T19:26:41.992721Z",
     "shell.execute_reply": "2021-05-09T19:26:41.991805Z",
     "shell.execute_reply.started": "2021-05-09T19:26:39.984578Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scoping_simulations.model.Subgoal_Planning_Agent import *\n",
    "import scoping_simulations.utils.blockworld as bw\n",
    "import scoping_simulations.utils.blockworld_library as bl\n",
    "from scoping_simulations.stimuli.tower_generator import TowerGenerator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import sem as sem\n",
    "import math\n",
    "\n",
    "import itertools\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import p_tqdm\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:26:42.015126Z",
     "iopub.status.busy": "2021-05-09T19:26:42.014646Z",
     "iopub.status.idle": "2021-05-09T19:26:42.031460Z",
     "shell.execute_reply": "2021-05-09T19:26:42.028746Z",
     "shell.execute_reply.started": "2021-05-09T19:26:42.015071Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "def str2array(s):\n",
    "    #strip \"array\" and parentheses\n",
    "    s=re.sub('\\[array\\(', '', s.strip())\n",
    "    s=re.sub('\\)]', '', s.strip())\n",
    "    # Remove space after [\n",
    "    s=re.sub('\\[ +', '[', s.strip())\n",
    "    # Replace commas and spaces\n",
    "    s=re.sub('[,\\s]+', ', ', s)\n",
    "    return np.array(ast.literal_eval(s))\n",
    "\n",
    "def str2list(s):\n",
    "    if s is np.nan: return s\n",
    "    #strip \"array\" and parentheses\n",
    "    s=re.sub('\\[array\\(', '', s.strip())\n",
    "    s=re.sub('\\)]', '', s.strip())\n",
    "    # Remove space after [\n",
    "    s=re.sub('\\[ +', '[', s.strip())\n",
    "    # Replace commas and spaces\n",
    "    s=re.sub('[,\\s]+', ', ', s)\n",
    "    return list(ast.literal_eval(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:26:42.035118Z",
     "iopub.status.busy": "2021-05-09T19:26:42.034495Z",
     "iopub.status.idle": "2021-05-09T19:26:42.042792Z",
     "shell.execute_reply": "2021-05-09T19:26:42.041368Z",
     "shell.execute_reply.started": "2021-05-09T19:26:42.035059Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#helper function for pd.agg\n",
    "def item(x):\n",
    "    return x.tail(1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:26:42.045165Z",
     "iopub.status.busy": "2021-05-09T19:26:42.044567Z",
     "iopub.status.idle": "2021-05-09T19:26:42.075037Z",
     "shell.execute_reply": "2021-05-09T19:26:42.072336Z",
     "shell.execute_reply.started": "2021-05-09T19:26:42.045072Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#inline plots\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot styling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:26:43.210787Z",
     "iopub.status.busy": "2021-05-09T19:26:43.210399Z",
     "iopub.status.idle": "2021-05-09T19:26:43.216734Z",
     "shell.execute_reply": "2021-05-09T19:26:43.215060Z",
     "shell.execute_reply.started": "2021-05-09T19:26:43.210750Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (7,7)\n",
    "plt.rcParams.update({'font.size': 26})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:26:43.535143Z",
     "iopub.status.busy": "2021-05-09T19:26:43.534614Z",
     "iopub.status.idle": "2021-05-09T19:26:43.543120Z",
     "shell.execute_reply": "2021-05-09T19:26:43.541115Z",
     "shell.execute_reply.started": "2021-05-09T19:26:43.535089Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "# plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Helvetica']\n",
    "rc('text.latex', preamble=r'\\usepackage{tgheros} \\usepackage{newtxsf} \\renewcommand{\\familydefault}{\\sfdefault} \\usepackage{mathastext}') #sets the font via latex preambleâ€”only way to autoset tick labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:26:43.754105Z",
     "iopub.status.busy": "2021-05-09T19:26:43.753798Z",
     "iopub.status.idle": "2021-05-09T19:26:43.759475Z",
     "shell.execute_reply": "2021-05-09T19:26:43.758090Z",
     "shell.execute_reply.started": "2021-05-09T19:26:43.754071Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 20)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.min_rows', 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "Let's load the results of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:26:44.227583Z",
     "iopub.status.busy": "2021-05-09T19:26:44.227112Z",
     "iopub.status.idle": "2021-05-09T19:26:44.238928Z",
     "shell.execute_reply": "2021-05-09T19:26:44.237780Z",
     "shell.execute_reply.started": "2021-05-09T19:26:44.227530Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_paths = [\n",
    "    # \"RLDM_scoping_BFS_experiment.csv\",\n",
    "    \"RLDM_full_decomp_experiment.csv\",\n",
    "    # \"RLDM_scoping_experiment.csv\",\n",
    "    # \"RLDM_lookahead_scoping_experiment.csv\",\n",
    "    # \"RLDM_long_sequences_experiment.csv\",\n",
    "    # \"RLDM_scoping_absolute_max_size_experiment.csv\",\n",
    "    \"RLDM_scoping_window_size_incremental_experiment.csv\",\n",
    "    \"RLDM_scoping_window_size_lookahead_experiment.csv\",\n",
    "    \"RLDM_longer_seqs_experiment.csv\",\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:26:44.524520Z",
     "iopub.status.busy": "2021-05-09T19:26:44.524087Z",
     "iopub.status.idle": "2021-05-09T19:27:17.205006Z",
     "shell.execute_reply": "2021-05-09T19:27:17.203628Z",
     "shell.execute_reply.started": "2021-05-09T19:26:44.524473Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load all experiments as one dataframe from CSV\n",
    "dfs = [pd.read_csv(os.path.join(df_dir,l)) for l in df_paths]\n",
    "print(\"Read {} dataframes: {}\".format(len(dfs), df_paths))\n",
    "# merge dfs\n",
    "df = pd.concat(dfs)\n",
    "print(\"Merged dataframes: {}\".format(df.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill a few missing rows from agent labels\n",
    "# helper function to pull out the size from the label\n",
    "def get_size(label):\n",
    "    try:\n",
    "        label = label.split('size=')[1]\n",
    "        str_number = label.split(' ')[0]\n",
    "        number = int(str_number)\n",
    "    except:\n",
    "        number = np.nan\n",
    "    return number\n",
    "# helper function to pull out the size from the label\n",
    "def get_lambda(label):\n",
    "    try:\n",
    "        label = label.split('lambda=')[1]\n",
    "        str_number = label.split(' ')[0]\n",
    "        number = int(str_number)\n",
    "    except:\n",
    "        number = np.nan\n",
    "    return number\n",
    "def get_subgoal_seq_length(label):\n",
    "    try:\n",
    "        label = label.split('Full Subgoal Decomposition ')[1]\n",
    "        number = int(label)\n",
    "    except:\n",
    "        number = np.nan\n",
    "    return number\n",
    "df['max_subgoal_size'] = df['label'].apply(get_size)\n",
    "df['lambda'] = df['label'].apply(get_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many runs do we have for each agent? Should be the same across the board\n",
    "df[df['final_row']]['label'].value_counts().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we have differing solutions depending on random seed? 1 if no, higher numbers if yes. That should mean we can do bootstrapping like before\n",
    "df[(df['label'] == \"Full Subgoal Decomposition 3\") & (df['final_row'])].groupby('world')['blockmap'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't want lambda != 0\n",
    "df = df[~((df['c_weight'] == 1.) & (df['label'].str.contains(\"Scoping\")))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and we don't want the 32 size scoper either\n",
    "df = df[~(df['label'].str.contains(\"max size=32\"))]\n",
    "df = df[~(df['label'].str.contains(\"max size=24\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do horrendous things to sort this mess\n",
    "df['label'] = df['label'].apply(lambda x: x.replace('size=4', 'size=04').replace('size=8', 'size=08'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pretty up the labels and order alphabetically by them. (Only run once after loading the dataframes from disk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACKS\n",
    "df['note'] = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many observations do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:27:35.798188Z",
     "iopub.status.busy": "2021-05-09T19:27:35.797781Z",
     "iopub.status.idle": "2021-05-09T19:27:35.819084Z",
     "shell.execute_reply": "2021-05-09T19:27:35.817467Z",
     "shell.execute_reply.started": "2021-05-09T19:27:35.798138Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['note'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did we cover the same worlds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('note')['world'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to be sure, the worlds are the same everywhere, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this will only work if the .pkl has been read\n",
    "for world in df['world'].unique():\n",
    "    try:\n",
    "        silhouettes = [w.silhouette for w in df[df['world']==world]['_world']]\n",
    "    except KeyError:\n",
    "        print(\"No world object found\")\n",
    "        break\n",
    "    first_s = silhouettes[0]\n",
    "    for i in range(1,len(silhouettes)):\n",
    "        if not np.all(silhouettes[i] == first_s):\n",
    "            print(\"World {} has different silhouettes!\".format(world))\n",
    "            print(world)\n",
    "            print(first_s)\n",
    "            print(silhouettes[i])\n",
    "            break\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating `fdf` with only outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T23:05:46.559033Z",
     "iopub.status.busy": "2021-05-09T23:05:46.558664Z",
     "iopub.status.idle": "2021-05-09T23:05:46.565475Z",
     "shell.execute_reply": "2021-05-09T23:05:46.564261Z",
     "shell.execute_reply.started": "2021-05-09T23:05:46.558997Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extraction functions\n",
    "def CI95(data): #this is NOT bootstrapped\n",
    "#     return st.t.interval(alpha=0.95,df=len(data)-1,loc=np.mean(data),scale=st.sem(data))\n",
    "    return tuple(np.percentile(data,[2.5,97.5]))\n",
    "\n",
    "def names(list_names):\n",
    "    if list_names is np.nan: return np.nan\n",
    "    return [g for g in list_names if g is not np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a few things to add helpful columns and such\n",
    "# use either solution_cost or states_evaluated as cost\n",
    "df['cost'] = np.maximum(df['partial_solution_cost'].fillna(0),\n",
    "                        df['states_evaluated'].fillna(0))\n",
    "# do the same for total cost\n",
    "df['total_cost'] = np.maximum(df['all_sequences_planning_cost'].fillna(\n",
    "    0), df['states_evaluated'].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to group by scoping/full subgoal decomposition agent\n",
    "def get_agent_type(label):\n",
    "    if \"Incremental Scoping\" in label: return \"Incremental Scoping\"\n",
    "    if \"Lookahead Scoping\" in label: return \"Lookahead Scoping\"\n",
    "    if \"Best First\" in label: return \"Action level\"\n",
    "    if \"Full Subgoal Decomposition\" in label: return \"Full Subgoal Decomposition\"\n",
    "    else: return np.nan\n",
    "\n",
    "df['agent_type'] = df['label'].apply(get_agent_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backfill costs for no subgoal agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:27:35.841570Z",
     "iopub.status.busy": "2021-05-09T19:27:35.841181Z",
     "iopub.status.idle": "2021-05-09T19:30:21.036059Z",
     "shell.execute_reply": "2021-05-09T19:30:21.034311Z",
     "shell.execute_reply.started": "2021-05-09T19:27:35.841536Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fdf holds final rows for every run\n",
    "fdf = df.groupby('run_ID').agg({\n",
    "        'agent': 'first',\n",
    "        'agent_type': item,\n",
    "        'c_weight': 'first',\n",
    "        'label': 'first',\n",
    "        'note': item,\n",
    "        'world': item,\n",
    "        'lambda': item,\n",
    "        'max_subgoal_size': item,\n",
    "        'action': 'count',\n",
    "        'blockmap': 'last',\n",
    "        'states_evaluated': ['sum', 'mean', sem],\n",
    "        'planning_cost': ['sum', 'mean', sem], \n",
    "        'partial_planning_cost': ['sum', 'mean', sem], # the planning cost of the sequence as far as acted\n",
    "        'partial_solution_cost': ['sum', 'mean', sem],\n",
    "        'solution_cost': ['sum', 'mean', sem],\n",
    "        'all_sequences_planning_cost': ['sum', 'mean', sem],\n",
    "        'num_subgoals_acted': ['sum', 'mean', sem],\n",
    "        'perfect': 'last',\n",
    "        'planning_step': 'max',\n",
    "        'cost': ['sum', 'mean', sem],\n",
    "        'total_cost': ['sum', 'mean', sem],\n",
    "})\n",
    "\n",
    "#flatten the dataframe to remove multi-index for next groupby\n",
    "fdf.columns = [' '.join(col).strip() for col in fdf.columns.values]\n",
    "fdf.reset_index(inplace=True)\n",
    "# What is the number of blocks used?\n",
    "fdf['num_blocks'] = fdf['blockmap last'].apply(lambda x: np.max(str2array(x)))\n",
    "#store note order as categorical to ensure sort\n",
    "# fdf['note item'] = pd.Categorical(fdf['note item'],NOTE_ORDER) #restore the order of column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:30:21.063969Z",
     "iopub.status.busy": "2021-05-09T19:30:21.062457Z",
     "iopub.status.idle": "2021-05-09T19:30:21.082505Z",
     "shell.execute_reply": "2021-05-09T19:30:21.081141Z",
     "shell.execute_reply.started": "2021-05-09T19:30:21.063894Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#as a sanity check, how many runs per label?\n",
    "fdf['note item'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:30:21.086570Z",
     "iopub.status.busy": "2021-05-09T19:30:21.086023Z",
     "iopub.status.idle": "2021-05-09T19:30:21.331595Z",
     "shell.execute_reply": "2021-05-09T19:30:21.329737Z",
     "shell.execute_reply.started": "2021-05-09T19:30:21.086473Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# condition on winning solving the world\n",
    "wfdf = fdf[fdf['perfect last']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:36:43.168447Z",
     "iopub.status.busy": "2021-05-09T19:36:43.166832Z",
     "iopub.status.idle": "2021-05-09T19:36:43.176053Z",
     "shell.execute_reply": "2021-05-09T19:36:43.173111Z",
     "shell.execute_reply.started": "2021-05-09T19:36:43.168381Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set random seed\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:46:33.729089Z",
     "iopub.status.busy": "2021-05-09T19:46:33.728805Z",
     "iopub.status.idle": "2021-05-09T19:46:33.911615Z",
     "shell.execute_reply": "2021-05-09T19:46:33.910592Z",
     "shell.execute_reply.started": "2021-05-09T19:46:33.729053Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bootstrap(cond_df, column, stat_function = np.mean, CIs = [2.5,97.5], iterations = 1000, show_tqdm = True):\n",
    "    \"\"\"Bootstrap by choosing one attempt for each structure from the given df. \n",
    "    The given df should only contain rows for the relevant algorithm/conditions.\n",
    "    Returns mean and CI of mean.\"\"\"\n",
    "    measurements = np.zeros(iterations)\n",
    "    world_masks = [cond_df['world item'] == w for w in cond_df['world item'].unique()]\n",
    "    for i in tqdm(range(iterations), leave=False, disable = not show_tqdm):\n",
    "        #sample one simulated run over all structures\n",
    "        run = [random.choice(list(cond_df[w][column])) for w in world_masks]\n",
    "        assert len(run) == len(world_masks)\n",
    "        #save that run\n",
    "        measurements[i] = stat_function(run)\n",
    "    #compute mean and CI over measurements\n",
    "    return np.mean(measurements),np.percentile(measurements, CIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent level stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create `agent_df` with bootstrapped means and their CIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS = 1000 # 1000 for final paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:37:03.396722Z",
     "iopub.status.busy": "2021-05-09T19:37:03.396212Z",
     "iopub.status.idle": "2021-05-09T19:39:27.767565Z",
     "shell.execute_reply": "2021-05-09T19:39:27.766291Z",
     "shell.execute_reply.started": "2021-05-09T19:37:03.396664Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#which columns do we want in our bootstrapped agent_df?\n",
    "columns = ['partial_planning_cost sum',\n",
    "    'partial_planning_cost mean',\n",
    "    'partial_solution_cost sum',\n",
    "    'cost sum',\n",
    "    'total_cost sum',\n",
    "    'partial_solution_cost mean',\n",
    "    'planning_cost sum',\n",
    "    'planning_cost mean',\n",
    "    'all_sequences_planning_cost sum',\n",
    "    'all_sequences_planning_cost mean',\n",
    "    'num_subgoals_acted sum' ,\n",
    "    'num_blocks']\n",
    "\n",
    "#initialize df\n",
    "# agent_df = pd.DataFrame(columns=pd.MultiIndex.from_product([columns,['mean','CI95']]))\n",
    "rows = {}\n",
    "\n",
    "for agent in wfdf['note item'].unique():\n",
    "    new_row = {('note item',''): agent}\n",
    "    for column in columns:\n",
    "        print(agent, column, end=\"\\r\")\n",
    "        #bootstrap\n",
    "        mean,CI = bootstrap(wfdf[wfdf['note item'] == agent],column, iterations=ITERATIONS)\n",
    "        #insert into dictionary\n",
    "        new_row[(column,'mean')] = mean\n",
    "        new_row[(column,'CI95')] = np.array(CI)\n",
    "        clear_output()\n",
    "    rows[agent] = new_row\n",
    "    \n",
    "#create df\n",
    "agent_df = pd.DataFrame(rows).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the same df, but for all runs to be able to check rate of success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:39:27.853781Z",
     "iopub.status.busy": "2021-05-09T19:39:27.853122Z",
     "iopub.status.idle": "2021-05-09T19:41:19.718932Z",
     "shell.execute_reply": "2021-05-09T19:41:19.718034Z",
     "shell.execute_reply.started": "2021-05-09T19:39:27.853690Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#which columns do we want in our bootstrapped a_agent_df?\n",
    "columns = ['perfect last']\n",
    "\n",
    "#initialize df\n",
    "# agent_df = pd.DataFrame(columns=pd.MultiIndex.from_product([columns,['mean','CI95']]))\n",
    "rows = {}\n",
    "\n",
    "for agent in wfdf['note item'].unique():\n",
    "    new_row = {('note item',''): agent}\n",
    "    for column in columns:\n",
    "        print(agent, column, end=\"\\r\")\n",
    "        #bootstrap\n",
    "        mean,CI = bootstrap(fdf[fdf['note item'] == agent],column, iterations=ITERATIONS)\n",
    "        #insert into dictionary\n",
    "        new_row[(column,'mean')] = mean\n",
    "        new_row[(column,'CI95')] = np.array(CI)\n",
    "        clear_output()\n",
    "    rows[agent] = new_row\n",
    "    \n",
    "#create df\n",
    "a_agent_df = pd.DataFrame(rows).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_agent_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we also want a way to group agents together for statistics across agent types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which columns do we want in our bootstrapped agent_df?\n",
    "columns = ['partial_planning_cost sum',\n",
    "    'partial_planning_cost mean',\n",
    "    'partial_solution_cost sum',\n",
    "    'cost sum',\n",
    "    'total_cost sum',\n",
    "    'partial_solution_cost mean',\n",
    "    'planning_cost sum',\n",
    "    'planning_cost mean',\n",
    "    'all_sequences_planning_cost sum',\n",
    "    'all_sequences_planning_cost mean',\n",
    "    'num_subgoals_acted sum' ,\n",
    "    'num_blocks']\n",
    "\n",
    "#initialize df\n",
    "# agent_df = pd.DataFrame(columns=pd.MultiIndex.from_product([columns,['mean','CI95']]))\n",
    "rows = {}\n",
    "\n",
    "for agent_type in wfdf['agent_type item'].unique():\n",
    "    new_row = {('agent_type item',''): agent_type}\n",
    "    for column in columns:\n",
    "        print(agent_type, column, end=\"\\r\")\n",
    "        #bootstrap\n",
    "        mean,CI = bootstrap(wfdf[wfdf['agent_type item'] == agent_type],column, iterations=ITERATIONS)\n",
    "        #insert into dictionary\n",
    "        new_row[(column,'mean')] = mean\n",
    "        new_row[(column,'CI95')] = np.array(CI)\n",
    "        clear_output()\n",
    "    rows[agent_type] = new_row\n",
    "    \n",
    "#create df\n",
    "agent_type_df = pd.DataFrame(rows).transpose()\n",
    "\n",
    "#which columns do we want in our bootstrapped a_agent_df?\n",
    "columns = ['perfect last']\n",
    "\n",
    "#initialize df\n",
    "# agent_df = pd.DataFrame(columns=pd.MultiIndex.from_product([columns,['mean','CI95']]))\n",
    "rows = {}\n",
    "\n",
    "for agent_type in wfdf['agent_type item'].unique():\n",
    "    new_row = {('agent_type item',''): agent_type}\n",
    "    for column in columns:\n",
    "        print(agent_type, column, end=\"\\r\")\n",
    "        #bootstrap\n",
    "        mean,CI = bootstrap(fdf[fdf['agent_type item'] == agent_type],column, iterations=ITERATIONS)\n",
    "        #insert into dictionary\n",
    "        new_row[(column,'mean')] = mean\n",
    "        new_row[(column,'CI95')] = np.array(CI)\n",
    "        clear_output()\n",
    "    rows[agent_type] = new_row\n",
    "    \n",
    "#create df\n",
    "a_agent_type_df = pd.DataFrame(rows).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_type_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_agent_type_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:41:19.743559Z",
     "iopub.status.busy": "2021-05-09T19:41:19.743149Z",
     "iopub.status.idle": "2021-05-09T19:41:23.585599Z",
     "shell.execute_reply": "2021-05-09T19:41:23.584878Z",
     "shell.execute_reply.started": "2021-05-09T19:41:19.743528Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # these are just for exploration\n",
    "\n",
    "# Ys = agent_df.dropna()['all_sequences_planning_cost sum']['mean']\n",
    "# CI95s = np.array([list(x) for x in agent_df.dropna()['all_sequences_planning_cost sum']['CI95']]).T\n",
    "# plt.bar(agent_df.dropna().index,Ys,yerr=np.array([abs(Ys - CI95s[0]),abs(Ys - CI95s[1])]))\n",
    "# plt.title(\"Mean sum total planning cost over all sequences\")\n",
    "# plt.ylabel(\"States evaluated\")\n",
    "# # plt.yscale('log')\n",
    "# plt.xticks(agent_df.dropna().index, agent_df.dropna()['note item'], rotation=90, fontsize=14)\n",
    "# plt.show()\n",
    "\n",
    "# Ys = agent_df.dropna()['all_sequences_planning_cost mean']['mean']\n",
    "# CI95s = np.array([list(x) for x in agent_df.dropna()['all_sequences_planning_cost mean']['CI95']]).T\n",
    "# plt.bar(agent_df.dropna().index,Ys,yerr=np.array([abs(Ys - CI95s[0]),abs(Ys - CI95s[1])]))\n",
    "# plt.title(\"Mean mean total planning cost over all sequences\")\n",
    "# plt.ylabel(\"States evaluated\")\n",
    "# # plt.yscale('log')\n",
    "# plt.xticks(agent_df.dropna().index, agent_df.dropna()['note item'], rotation=90, fontsize=14)\n",
    "# plt.show()\n",
    "\n",
    "# Ys = agent_df.dropna()['planning_cost sum']['mean']\n",
    "# CI95s = np.array([list(x) for x in agent_df.dropna()['planning_cost sum']['CI95']]).T\n",
    "# plt.bar(agent_df.dropna().index,Ys,yerr=np.array([abs(Ys - CI95s[0]),abs(Ys - CI95s[1])]))\n",
    "# plt.title(\"Mean sum of planning costs for chosen sequence\")\n",
    "# plt.ylabel(\"States evaluated\")\n",
    "# # plt.yscale('log')\n",
    "# plt.xticks(agent_df.dropna().index, agent_df.dropna()['note item'], rotation=90, fontsize=14)\n",
    "# plt.show()\n",
    "\n",
    "# Ys = agent_df.dropna()['partial_planning_cost sum']['mean']\n",
    "# CI95s = np.array([list(x) for x in agent_df.dropna()['partial_planning_cost sum']['CI95']]).T\n",
    "# plt.bar(agent_df.dropna().index,Ys,yerr=np.array([abs(Ys - CI95s[0]),abs(Ys - CI95s[1])]))\n",
    "# plt.title(\"Mean sum of partial planning costs for chosen sequence\")\n",
    "# plt.ylabel(\"States evaluated\")\n",
    "# # plt.yscale('log')\n",
    "# plt.xticks(agent_df.dropna().index, agent_df.dropna()['note item'], rotation=90, fontsize=14)\n",
    "# plt.show()\n",
    "\n",
    "# Ys = agent_df.dropna()['planning_cost mean']['mean']\n",
    "# CI95s = np.array([list(x) for x in agent_df.dropna()['planning_cost mean']['CI95']]).T\n",
    "# plt.bar(agent_df.dropna().index,Ys,yerr=np.array([abs(Ys - CI95s[0]),abs(Ys - CI95s[1])]))\n",
    "# plt.title(\"Mean mean of planning costs for chosen sequence\")\n",
    "# plt.ylabel(\"States evaluated\")\n",
    "# # plt.yscale('log')\n",
    "# plt.xticks(agent_df.dropna().index, agent_df.dropna()['note item'], rotation=90, fontsize=14)\n",
    "# plt.show()\n",
    "\n",
    "# Ys = agent_df.dropna()['partial_planning_cost mean']['mean']\n",
    "# CI95s = np.array([list(x) for x in agent_df.dropna()['planning_cost mean']['CI95']]).T\n",
    "# plt.bar(agent_df.dropna().index,Ys,yerr=np.array([abs(Ys - CI95s[0]),abs(Ys - CI95s[1])]))\n",
    "# plt.title(\"Mean mean of partial planning costs for chosen sequence\")\n",
    "# plt.ylabel(\"States evaluated\")\n",
    "# # plt.yscale('log')\n",
    "# plt.xticks(agent_df.dropna().index, agent_df.dropna()['note item'], rotation=90, fontsize=14)\n",
    "# plt.show()\n",
    "\n",
    "# Ys = agent_df.dropna()['partial_solution_cost mean']['mean']\n",
    "# CI95s = np.array([list(x) for x in agent_df.dropna()['partial_solution_cost mean']['CI95']]).T\n",
    "# plt.bar(agent_df.dropna().index,Ys,yerr=np.array([abs(Ys - CI95s[0]),abs(Ys - CI95s[1])]))\n",
    "# plt.title(\"Mean solution cost\")\n",
    "# plt.ylabel(\"States evaluated\")\n",
    "# # plt.yscale('log')\n",
    "# plt.xticks(agent_df.dropna().index, agent_df.dropna()['note item'], rotation=90, fontsize=14)\n",
    "# plt.show()\n",
    "\n",
    "# Ys = agent_df.dropna()['num_blocks']['mean']\n",
    "# CI95s = np.array([list(x) for x in agent_df.dropna()['num_blocks']['CI95']]).T\n",
    "# plt.bar(agent_df.dropna().index,Ys,yerr=np.array([abs(Ys - CI95s[0]),abs(Ys - CI95s[1])]))\n",
    "# plt.title(\"Number of blocks used\")\n",
    "# plt.ylabel(\"Number of blocks\")\n",
    "# # plt.yscale('log')\n",
    "# plt.xticks(agent_df.dropna().index, agent_df.dropna()['note item'], rotation=90, fontsize=14)\n",
    "# plt.show()\n",
    "\n",
    "# Ys = agent_df.dropna()['num_subgoals_acted sum']['mean']\n",
    "# CI95s = np.array([list(x) for x in agent_df.dropna()['num_subgoals_acted sum']['CI95']]).T\n",
    "# plt.bar(agent_df.dropna().index,Ys,yerr=np.array([abs(Ys - CI95s[0]),abs(Ys - CI95s[1])]))\n",
    "# plt.title(\"Mean number of subgoals\")\n",
    "# plt.ylabel(\"Number of subgoals acted out\")\n",
    "# # plt.savefig(\"../results/plots/lookahead_n_subgoals\")\n",
    "# plt.xticks(agent_df.dropna().index, agent_df.dropna()['note item'], rotation=90, fontsize=14)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar plot of success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at rate of success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:41:23.587598Z",
     "iopub.status.busy": "2021-05-09T19:41:23.587190Z",
     "iopub.status.idle": "2021-05-09T19:41:24.011896Z",
     "shell.execute_reply": "2021-05-09T19:41:24.010948Z",
     "shell.execute_reply.started": "2021-05-09T19:41:23.587547Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "column = 'perfect last'\n",
    "CIs = np.array([list(x) for x in a_agent_df.dropna()[column]['CI95']]).T\n",
    "Xs = a_agent_df.dropna()[column]['mean'].index\n",
    "Ys = a_agent_df.dropna()[column]['mean']\n",
    "Error = np.array([abs(Ys - CIs[0]),abs(Ys - CIs[1])])\n",
    "\n",
    "plt.bar(Xs,Ys,yerr=Error)\n",
    "plt.title(\"Proportion perfect reconstruction\")\n",
    "plt.ylabel(\"Proportion perfect reconstruction\")\n",
    "# plt.xlabel(\"Sequence length\")\n",
    "plt.xticks(a_agent_df.dropna().index, a_agent_df.dropna()['note item'], rotation=90, fontsize=14) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats on success and cost ðŸ’Ž"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:55:28.395382Z",
     "iopub.status.busy": "2021-05-09T19:55:28.395056Z",
     "iopub.status.idle": "2021-05-09T19:55:28.408441Z",
     "shell.execute_reply": "2021-05-09T19:55:28.407254Z",
     "shell.execute_reply.started": "2021-05-09T19:55:28.395356Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_agent_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:55:53.619989Z",
     "iopub.status.busy": "2021-05-09T19:55:53.619724Z",
     "iopub.status.idle": "2021-05-09T19:55:53.667504Z",
     "shell.execute_reply": "2021-05-09T19:55:53.666539Z",
     "shell.execute_reply.started": "2021-05-09T19:55:53.619962Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapped differences between agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bootstrapping difference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T00:57:09.590312Z",
     "iopub.status.busy": "2021-05-11T00:57:09.589523Z",
     "iopub.status.idle": "2021-05-11T00:57:09.647932Z",
     "shell.execute_reply": "2021-05-11T00:57:09.644796Z",
     "shell.execute_reply.started": "2021-05-11T00:57:09.590184Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bootstrap_difference(A_df, B_df, column, stat_function = np.mean, CIs = [2.5,97.5], iterations = 1000):\n",
    "    \"\"\"Bootstrap by choosing one attempt for each structure from the given df for each A and B, then taking the difference. \n",
    "    The given df should only contain rows for the relevant algorithm/conditions.\n",
    "    Returns mean and CI of mean.\"\"\"\n",
    "    measurements = np.zeros(iterations)\n",
    "    A_world_masks = [A_df['world item'] == w for w in sorted(A_df['world item'].unique())]\n",
    "    B_world_masks = [B_df['world item'] == w for w in sorted(B_df['world item'].unique())]\n",
    "    for i in tqdm(range(iterations),leave=False):\n",
    "        #sample one simulated run over all structures\n",
    "        runA = [random.choice(list(A_df[w][column])) for w in A_world_masks]\n",
    "        runB = [random.choice(list(B_df[w][column])) for w in B_world_masks]        \n",
    "        #compute differences between the means of two runs\n",
    "        measurements[i] = stat_function(runA)-stat_function(runB)\n",
    "\n",
    "    #compute mean and CI over measurements\n",
    "    p = np.sum(np.array(measurements) < 0)/(len(measurements) *2) #p value\n",
    "    return np.mean(measurements),np.percentile(measurements, CIs), p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoping vs Full\n",
    "The **action cost** of subgoal planning is lower than the **cost** of full planning. \n",
    "\n",
    "One sided Welsh t test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['note'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1 = \"Full Subgoal Decomposition 3\" \n",
    "agent2 = \"Best First\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T00:57:09.659719Z",
     "iopub.status.busy": "2021-05-11T00:57:09.658844Z",
     "iopub.status.idle": "2021-05-11T00:57:09.872929Z",
     "shell.execute_reply": "2021-05-11T00:57:09.869052Z",
     "shell.execute_reply.started": "2021-05-11T00:57:09.659659Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = wfdf[wfdf['note item']==agent1]['partial_planning_cost sum']\n",
    "b = wfdf[wfdf['note item']==agent2]['partial_planning_cost sum']\n",
    "tStat, pValue = stats.ttest_ind(a, b,equal_var = False) #run independent sample T-Test\n",
    "pValue = pValue/2 #we're doing a one sided test here\n",
    "print(\"P-Value:{0} T-Statistic:{1}, DF: {2}\".format(pValue,tStat,len(a)+len(b)-2)) #print the P-Value and the T-Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapped difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T00:57:09.879215Z",
     "iopub.status.busy": "2021-05-11T00:57:09.878712Z",
     "iopub.status.idle": "2021-05-11T00:59:53.076542Z",
     "shell.execute_reply": "2021-05-11T00:59:53.074959Z",
     "shell.execute_reply.started": "2021-05-11T00:57:09.879156Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bootstrapped pairwise\n",
    "column = 'partial_planning_cost sum'\n",
    "mean, CI, p = bootstrap_difference(\n",
    "    wfdf[wfdf['note item'] == agent1],\n",
    "    wfdf[wfdf['note item'] == agent2],\n",
    "    column)\n",
    "print(\"mean difference between {} & {} on {}:\\n\".format(agent1, agent2, column),\n",
    "      mean, \" p:\", p, \" CI:\", CI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **subgoal cost** of scoping planning is lower than the **subgoal cost** of full planning. \n",
    "\n",
    "One sided Welsh t test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T00:59:53.079798Z",
     "iopub.status.busy": "2021-05-11T00:59:53.079265Z",
     "iopub.status.idle": "2021-05-11T00:59:53.163748Z",
     "shell.execute_reply": "2021-05-11T00:59:53.160206Z",
     "shell.execute_reply.started": "2021-05-11T00:59:53.079742Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = wfdf[wfdf['note item']==agent1]['all_sequences_planning_cost sum']\n",
    "b = wfdf[wfdf['note item']==agent2]['all_sequences_planning_cost sum']\n",
    "tStat, pValue = stats.ttest_ind(a, b,equal_var = False) #run independent sample T-Test\n",
    "pValue = pValue/2 #we're doing a one sided test here\n",
    "print(\"P-Value:{0} T-Statistic:{1}, DF: {2}\".format(pValue,tStat,len(a)+len(b)-2)) #print the P-Value and the T-Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapped difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T00:59:53.169531Z",
     "iopub.status.busy": "2021-05-11T00:59:53.168922Z",
     "iopub.status.idle": "2021-05-11T01:03:08.023438Z",
     "shell.execute_reply": "2021-05-11T01:03:08.020026Z",
     "shell.execute_reply.started": "2021-05-11T00:59:53.169429Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#bootstrapped pairwise\n",
    "column = 'all_sequences_planning_cost sum'\n",
    "mean,CI,p = bootstrap_difference(\n",
    "    wfdf[wfdf['note item']==agent1],\n",
    "    wfdf[wfdf['note item']==agent2],\n",
    "    column)\n",
    "print(\"mean difference between {} & {} on {}:\\n\".format(agent1, agent2, column),\n",
    "      mean, \" p:\", p, \" CI:\", CI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The success of **scoping** planning is lower than the **success** of full planning:\n",
    "\n",
    "One sided Welsh t test:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**do the one's below as needed for the paper (or turn into a function)** âš ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T01:03:08.037909Z",
     "iopub.status.busy": "2021-05-11T01:03:08.033710Z",
     "iopub.status.idle": "2021-05-11T01:03:08.181719Z",
     "shell.execute_reply": "2021-05-11T01:03:08.179801Z",
     "shell.execute_reply.started": "2021-05-11T01:03:08.037790Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for agent in [\"BFS\",\"A*\"]:\n",
    "    print(agent)\n",
    "    a = fdf[fdf['note item']==agent1]['perfect last']\n",
    "    b = fdf[fdf['note item']==agent2]['perfect last']\n",
    "    tStat, pValue = stats.ttest_ind(a,b,equal_var = False) #run independent sample T-Test\n",
    "    pValue = pValue/2 #we're doing a one sided test here\n",
    "    print(\"P-Value:{0} T-Statistic:{1}, DF: {2}\".format(pValue,tStat,len(a)+len(b)-2)) #print the P-Value and the T-Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapped difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T01:03:08.194059Z",
     "iopub.status.busy": "2021-05-11T01:03:08.193461Z",
     "iopub.status.idle": "2021-05-11T01:06:06.851203Z",
     "shell.execute_reply": "2021-05-11T01:06:06.843761Z",
     "shell.execute_reply.started": "2021-05-11T01:03:08.194010Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#bootstrapped pairwise\n",
    "column = 'perfect last'\n",
    "a = \"Scoping\"\n",
    "b = \"Full\"\n",
    "for agent in [\"BFS\",\"A*\"]:\n",
    "    mean,CI,p = bootstrap_difference(\n",
    "        fdf[fdf['note item']==agent1],\n",
    "        fdf[fdf['note item']==agent2],\n",
    "        column)\n",
    "    print(\"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\")\n",
    "    print(agent,column)\n",
    "    print(\"mean difference:\",mean,\" p:\",p,\" CI:\",CI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoping uses more blocks than full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T01:06:06.924502Z",
     "iopub.status.busy": "2021-05-11T01:06:06.921586Z",
     "iopub.status.idle": "2021-05-11T01:09:34.490914Z",
     "shell.execute_reply": "2021-05-11T01:09:34.475996Z",
     "shell.execute_reply.started": "2021-05-11T01:06:06.924423Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#bootstrapped pairwise\n",
    "column = 'num_blocks'\n",
    "a = \"Scoping\"\n",
    "b = \"Full\"\n",
    "for agent in [\"BFS\",\"A*\"]:\n",
    "    mean,CI,p = bootstrap_difference(\n",
    "        fdf[fdf['note item']==agent1],\n",
    "        fdf[fdf['note item']==agent2],\n",
    "        column)\n",
    "    print(\"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\")\n",
    "    print(agent,column)\n",
    "    print(\"mean difference:\",mean,\" p:\",p,\" CI:\",CI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but fewer than action-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T01:12:42.416699Z",
     "iopub.status.busy": "2021-05-11T01:12:42.416029Z",
     "iopub.status.idle": "2021-05-11T01:15:55.389851Z",
     "shell.execute_reply": "2021-05-11T01:15:55.380787Z",
     "shell.execute_reply.started": "2021-05-11T01:12:42.416594Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#bootstrapped pairwise\n",
    "column = 'num_blocks'\n",
    "a = \"Scoping\"\n",
    "b = \"Action level\"\n",
    "for agent in [\"BFS\",\"A*\"]:\n",
    "    mean,CI,p = bootstrap_difference(\n",
    "        fdf[fdf['note item']==agent1],\n",
    "        fdf[fdf['note item']==agent2],\n",
    "        column)\n",
    "    print(\"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\")\n",
    "    print(agent,column)\n",
    "    print(\"mean difference:\",mean,\" p:\",p,\" CI:\",CI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full vs action level\n",
    "The **action cost** of full planning is lower than the **cost** of no subgoal planning. \n",
    "\n",
    "One sided Welsh t test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T01:09:34.517979Z",
     "iopub.status.busy": "2021-05-11T01:09:34.515910Z",
     "iopub.status.idle": "2021-05-11T01:09:34.661594Z",
     "shell.execute_reply": "2021-05-11T01:09:34.659840Z",
     "shell.execute_reply.started": "2021-05-11T01:09:34.517901Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for agent in [\"BFS\",\"A*\"]:\n",
    "    print(agent)\n",
    "    a = wfdf[wfdf['note item']==agent+\"\\nAction level\"]['partial_planning_cost sum']\n",
    "    b = wfdf[wfdf['note item']==agent2]['partial_planning_cost sum']\n",
    "    tStat, pValue = stats.ttest_ind(a, b,equal_var = False) #run independent sample T-Test\n",
    "    pValue = pValue/2 #we're doing a one sided test here\n",
    "    print(\"P-Value:{0} T-Statistic:{1}, DF: {2}\".format(pValue,tStat,len(a)+len(b)-2)) #print the P-Value and the T-Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapped difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T01:09:34.672089Z",
     "iopub.status.busy": "2021-05-11T01:09:34.669524Z",
     "iopub.status.idle": "2021-05-11T01:10:49.732302Z",
     "shell.execute_reply": "2021-05-11T01:10:49.730623Z",
     "shell.execute_reply.started": "2021-05-11T01:09:34.672015Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#bootstrapped pairwise\n",
    "column = 'partial_planning_cost sum'\n",
    "a = \"Action level\"\n",
    "b = \"Full\"\n",
    "for agent in [\"BFS\",\"A*\"]:\n",
    "    mean,CI,p = bootstrap_difference(\n",
    "        wfdf[wfdf['note item']==agent1],\n",
    "        wfdf[wfdf['note item']==agent2],\n",
    "        column)\n",
    "    print(\"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\")\n",
    "    print(agent,column)\n",
    "    print(\"mean difference:\",mean,\" p:\",p,\" CI:\",CI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The success of **full subgoal** planning is lower than the **success** of no subgoal planning:\n",
    "\n",
    "One sided Welsh t test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T01:10:49.735885Z",
     "iopub.status.busy": "2021-05-11T01:10:49.735336Z",
     "iopub.status.idle": "2021-05-11T01:10:49.767288Z",
     "shell.execute_reply": "2021-05-11T01:10:49.765775Z",
     "shell.execute_reply.started": "2021-05-11T01:10:49.735825Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for agent in [\"BFS\",\"A*\"]:\n",
    "    print(agent)\n",
    "    a = fdf[fdf['note item']==agent+\"\\nAction level\"]['perfect last']\n",
    "    b = fdf[fdf['note item']==agent2]['perfect last']\n",
    "    tStat, pValue = stats.ttest_ind(a,b,equal_var = False) #run independent sample T-Test\n",
    "    pValue = pValue/2 #we're doing a one sided test here\n",
    "    print(\"P-Value:{0} T-Statistic:{1}, DF: {2}\".format(pValue,tStat,len(a)+len(b)-2)) #print the P-Value and the T-Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapped difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T01:10:49.770632Z",
     "iopub.status.busy": "2021-05-11T01:10:49.770023Z",
     "iopub.status.idle": "2021-05-11T01:12:42.146763Z",
     "shell.execute_reply": "2021-05-11T01:12:42.145312Z",
     "shell.execute_reply.started": "2021-05-11T01:10:49.770591Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#bootstrapped pairwise\n",
    "column = 'perfect last'\n",
    "a = \"Action level\"\n",
    "b = \"Full\"\n",
    "for agent in [\"BFS\",\"A*\"]:\n",
    "    mean,CI,p = bootstrap_difference(\n",
    "        fdf[fdf['note item']==agent1],\n",
    "        fdf[fdf['note item']==agent2],\n",
    "        column)\n",
    "    print(\"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\")\n",
    "    print(agent,column)\n",
    "    print(\"mean difference:\",mean,\" p:\",p,\" CI:\",CI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Success/cost scatter plot ðŸ’Ž"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T20:29:09.652755Z",
     "iopub.status.busy": "2021-05-09T20:29:09.652453Z",
     "iopub.status.idle": "2021-05-09T20:29:09.658967Z",
     "shell.execute_reply": "2021-05-09T20:29:09.657148Z",
     "shell.execute_reply.started": "2021-05-09T20:29:09.652728Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #change the order of the dataframe\n",
    "# agent_df = agent_df.reindex([\n",
    "#      'A*\\nAction level',\n",
    "#      'A*\\nScoping',\n",
    "#      'A*\\nFull',\n",
    "#      'BFS\\nAction level',\n",
    "#      'BFS\\nScoping',\n",
    "#      'BFS\\nFull',\n",
    "#     ]\n",
    "# )\n",
    "# a_agent_df = a_agent_df.reindex([\n",
    "#      'A*\\nAction level',\n",
    "#      'A*\\nScoping',\n",
    "#      'A*\\nFull',\n",
    "#      'BFS\\nAction level',\n",
    "#      'BFS\\nScoping',\n",
    "#      'BFS\\nFull',\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_markers(label):\n",
    "    if 'Incremental' in label:\n",
    "        return 'o'\n",
    "    elif 'Lookahead' in label:\n",
    "        return 'h'\n",
    "    elif 'Best First' in label:\n",
    "        return 'D'\n",
    "    else:\n",
    "        return 's'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors(label):\n",
    "    if 'Incremental' in label:\n",
    "        return [43/255,108/255,162/255,]\n",
    "    elif 'Lookahead' in label:\n",
    "        return [150/255,43/255,162/255,]\n",
    "    elif 'Best First' in label:\n",
    "        return [42/255,132/255,94/255,]\n",
    "    else:\n",
    "        return [174/255,55/255,4/255,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connecting_agent_substrings = [\"Incremental\",\"Lookahead\",\"Full Subgoal Decomposition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_df.sort_index(inplace=True)\n",
    "a_agent_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_df['cost sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T20:29:12.102675Z",
     "iopub.status.busy": "2021-05-09T20:29:12.102220Z",
     "iopub.status.idle": "2021-05-09T20:29:12.639947Z",
     "shell.execute_reply": "2021-05-09T20:29:12.639358Z",
     "shell.execute_reply.started": "2021-05-09T20:29:12.102624Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "Xs = agent_df['cost sum']['mean'] # not solution cost?\n",
    "Ys = a_agent_df['perfect last']['mean']\n",
    "YCIs = np.array(a_agent_df['perfect last']['CI95']).T\n",
    "XCIs = np.array(agent_df['cost sum']['CI95']).T\n",
    "XCIs = np.array([list(x) for x in XCIs]).T\n",
    "YCIs = np.array([list(x) for x in YCIs]).T\n",
    "Xerr = np.array([abs(Xs - XCIs[0]),abs(Xs - XCIs[1])])\n",
    "Yerr = np.array([abs(Ys - YCIs[0]),abs(Ys - YCIs[1])])\n",
    "labels = agent_df.index.get_level_values(0)\n",
    "markers = {label:get_markers(label) for label in labels}\n",
    "\n",
    "\n",
    "plt.errorbar(Xs,Ys,xerr=Xerr,yerr=Yerr,linewidth = 0, elinewidth=3,ecolor='grey', alpha=0.3)\n",
    "sns.scatterplot(Xs, Ys, style = list(labels), markers = markers, s = 500, c=[get_colors(l) for l in labels], legend=False)\n",
    "for ss in connecting_agent_substrings:\n",
    "    plt.plot(Xs[labels.str.contains(ss)],Ys[labels.str.contains(ss)],alpha=0.6,c=get_colors(ss),linewidth=4)\n",
    "\n",
    "# we want little numbers with max_subgoal_size where applicable\n",
    "max_subgoal_sizes = [get_size(label) for label in labels]\n",
    "for i,label in enumerate(labels):\n",
    "    if 'Scoping' in label:\n",
    "        plt.text(Xs[i],Ys[i],str(max_subgoal_sizes[i]),fontsize=16, alpha=0.8, ha='center', va='center', color='white')\n",
    "seq_lengths = [get_subgoal_seq_length(label) for label in labels]\n",
    "for i,label in enumerate(labels):\n",
    "    if 'Full Subgoal Decomposition' in label:\n",
    "        # hack for overlapping labels\n",
    "        if seq_lengths[i] == 3: seq_lengths[i] = \"  3\"\n",
    "        if seq_lengths[i] == 4: seq_lengths[i] = \"4  \"\n",
    "        plt.text(Xs[i],Ys[i],str(seq_lengths[i]),fontsize=16, alpha=0.8, ha='center', va='center', color='white')\n",
    "\n",
    "axes = plt.gca()    \n",
    "plt.title(\"Success and\\naction planning cost\")\n",
    "plt.xlabel(\"Action planning cost\")\n",
    "plt.ylabel(\"Rate of perfect reconstruction\")\n",
    "plt.xscale('log')\n",
    "# plt.ylim(0,1.05)\n",
    "plt.savefig(\"../results/plots/scatter_success_planning_cost.pdf\",bbox_inches='tight')\n",
    "# remove legend\n",
    "plt.legend().remove()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this with total cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T20:29:25.344992Z",
     "iopub.status.busy": "2021-05-09T20:29:25.344740Z",
     "iopub.status.idle": "2021-05-09T20:29:25.845110Z",
     "shell.execute_reply": "2021-05-09T20:29:25.844482Z",
     "shell.execute_reply.started": "2021-05-09T20:29:25.344965Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "# we don't want to plot the action level planner here\n",
    "_agent_df = agent_df[~agent_df.index.get_level_values(0).str.contains(\"Best First\")]\n",
    "_a_agent_df = a_agent_df[~a_agent_df.index.get_level_values(0).str.contains(\"Best First\")]\n",
    "\n",
    "Xs = _agent_df['total_cost sum']['mean']\n",
    "Ys = _a_agent_df['perfect last']['mean']\n",
    "YCIs = np.array(_a_agent_df['perfect last']['CI95']).T\n",
    "XCIs = np.array(_agent_df['total_cost sum']['CI95']).T\n",
    "XCIs = np.array([list(x) for x in XCIs]).T\n",
    "YCIs = np.array([list(x) for x in YCIs]).T\n",
    "Xerr = np.array([abs(Xs - XCIs[0]),abs(Xs - XCIs[1])])\n",
    "Yerr = np.array([abs(Ys - YCIs[0]),abs(Ys - YCIs[1])])\n",
    "labels = _agent_df.index.get_level_values(0)\n",
    "markers = {label:get_markers(label) for label in labels}\n",
    "\n",
    "\n",
    "plt.errorbar(Xs,Ys,xerr=Xerr,yerr=Yerr,linewidth = 0, elinewidth=3,ecolor='grey', alpha=0.3)\n",
    "sns.scatterplot(Xs, Ys, style = list(labels), markers = markers, s = 500, c=[get_colors(l) for l in labels], legend=False)\n",
    "for ss in connecting_agent_substrings:\n",
    "    plt.plot(Xs[labels.str.contains(ss)],Ys[labels.str.contains(ss)],alpha=0.6,c=get_colors(ss),linewidth=4)\n",
    "\n",
    "# we want little numbers with max_subgoal_size where applicable\n",
    "max_subgoal_sizes = [get_size(label) for label in labels]\n",
    "for i,label in enumerate(labels):\n",
    "    if 'Scoping' in label:\n",
    "        plt.text(Xs[i],Ys[i],str(max_subgoal_sizes[i]),fontsize=16, alpha=0.8, ha='center', va='center', color='white')\n",
    "seq_lengths = [get_subgoal_seq_length(label) for label in labels]\n",
    "for i,label in enumerate(labels):\n",
    "    if 'Full Subgoal Decomposition' in label:\n",
    "        plt.text(Xs[i],Ys[i],str(seq_lengths[i]),fontsize=16, alpha=0.8, ha='center', va='center', color='white')\n",
    "\n",
    "axes = plt.gca()    \n",
    "plt.title(\"Success and\\nsubgoal planning cost\")\n",
    "plt.xlabel(\"Subgoal planning cost\")\n",
    "plt.ylabel(\"Rate of perfect reconstruction\")\n",
    "plt.xscale('log')\n",
    "# plt.ylim(0,max(Ys)*5)\n",
    "plt.savefig(\"../results/plots/scatter_success_subgoal_cost.pdf\",bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tower size analysis\n",
    "$\\lambda$ is replaced by tower size analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the complexity of the worlds\n",
    "# easiest to recreate them here\n",
    "block_library = bl.bl_nonoverlapping_simple\n",
    "generator = TowerGenerator(8, 8,\n",
    "                                                    block_library=block_library,\n",
    "                                                    seed=42,\n",
    "                                                    padding=(2, 0),\n",
    "                                                    num_blocks=lambda: random.randint(\n",
    "                                                        5, 10),\n",
    "                                                    physics=True,\n",
    "                                                    )\n",
    "NUM_TOWERS = 64\n",
    "towers = []\n",
    "for i in tqdm(range(NUM_TOWERS)):\n",
    "    towers.append(generator.generate())\n",
    "\n",
    "for i in range(len(towers)):\n",
    "    towers[i]['name'] = str(i)\n",
    "towers = {t['name']: t for t in towers}\n",
    "print(\"Made {} towers\".format(len(towers)))\n",
    "tower_lengths = {t['name']: len(t['blocks']) for t in towers.values()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split towers up into three groups\n",
    "easies = []\n",
    "hards = []\n",
    "percentiles = [np.percentile(list(tower_lengths.values()), i) for i in [33,66,99]]\n",
    "for tower in towers:\n",
    "    if tower_lengths[tower] < percentiles[0]:\n",
    "        easies.append(int(tower)) # we have to cast the tower to int for some bad reason.\n",
    "    elif tower_lengths[tower] > percentiles[1]:\n",
    "        hards.append(int(tower)) # we have to cast the tower to int for some bad reason.\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to boostrap an agent_df split up by tower size\n",
    "tower_agent_dfs = {}\n",
    "tower_a_agent_dfs = {}\n",
    "for cond, tower_list in {'small':easies,'large': hards}.items():\n",
    "    print(\"Making {} tower agent_df\".format(cond))\n",
    "    #which columns do we want in our bootstrapped agent_df?\n",
    "    columns = ['partial_planning_cost sum',\n",
    "        'partial_planning_cost mean',\n",
    "        'partial_solution_cost sum',\n",
    "        'cost sum',\n",
    "        'total_cost sum',\n",
    "        'partial_solution_cost mean',\n",
    "        'planning_cost sum',\n",
    "        'planning_cost mean',\n",
    "        'all_sequences_planning_cost sum',\n",
    "        'all_sequences_planning_cost mean',\n",
    "        'num_subgoals_acted sum' ,\n",
    "        'num_blocks']\n",
    "\n",
    "    #initialize df\n",
    "    # agent_df = pd.DataFrame(columns=pd.MultiIndex.from_product([columns,['mean','CI95']]))\n",
    "    rows = {}\n",
    "\n",
    "    for agent_type in wfdf['agent_type item'].unique():\n",
    "        new_row = {('agent_type item',''): agent_type}\n",
    "        for column in columns:\n",
    "            print(agent_type, column, end=\"\\r\")\n",
    "            #bootstrap\n",
    "            mean,CI = bootstrap(wfdf[wfdf['agent_type item'] == agent_type],column, iterations=ITERATIONS)\n",
    "            #insert into dictionary\n",
    "            new_row[(column,'mean')] = mean\n",
    "            new_row[(column,'CI95')] = np.array(CI)\n",
    "            clear_output()\n",
    "        rows[agent_type] = new_row\n",
    "        \n",
    "    #create df\n",
    "    tower_agent_dfs[cond] = pd.DataFrame(rows).transpose()\n",
    "\n",
    "    #which columns do we want in our bootstrapped a_agent_df?\n",
    "    columns = ['perfect last']\n",
    "\n",
    "    #initialize df\n",
    "    # agent_df = pd.DataFrame(columns=pd.MultiIndex.from_product([columns,['mean','CI95']]))\n",
    "    rows = {}\n",
    "\n",
    "    for agent_type in wfdf['agent_type item'].unique():\n",
    "        new_row = {('agent_type item',''): agent_type}\n",
    "        for column in columns:\n",
    "            print(agent_type, column, end=\"\\r\")\n",
    "            #bootstrap\n",
    "            mean,CI = bootstrap(fdf[fdf['agent_type item'] == agent_type],column, iterations=ITERATIONS)\n",
    "            #insert into dictionary\n",
    "            new_row[(column,'mean')] = mean\n",
    "            new_row[(column,'CI95')] = np.array(CI)\n",
    "            clear_output()\n",
    "        rows[agent_type] = new_row\n",
    "        \n",
    "    #create df\n",
    "    tower_a_agent_dfs[cond] = pd.DataFrame(rows).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tower_agent_dfs['small']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "for label in ['Full Subgoal Decomposition 3', 'Lookahead Scoping max size=16 lambda=0.0']:\n",
    "    ag_df = fdf[fdf['note item'] == label]\n",
    "    costs = dict(ag_df.groupby(['world item']).mean()['cost sum'])\n",
    "    # make a df\n",
    "    _world_cost_df = pd.DataFrame(list(costs.items()), columns=['world', 'cost'])\n",
    "    # add size to it\n",
    "    _world_cost_df['size'] = _world_cost_df['world'].apply(lambda x: tower_lengths[str(int(x))])\n",
    "    agg_w_df = _world_cost_df.groupby('size').mean()\n",
    "    jitters = (np.random.random(len(tower_lengths))-0.5)*0.25\n",
    "    # plot a scatter plot\n",
    "    plt.scatter(\n",
    "        y=list(costs.values()),\n",
    "        x=list(tower_lengths.values())+jitters,\n",
    "        c=get_colors(label),\n",
    "        # c=list(tower_lengths.values()),\n",
    "        label=label,\n",
    "        marker=get_markers(label),\n",
    "        alpha=0.6,\n",
    "        s=50,\n",
    "        )\n",
    "    # plot a line plot for average cost\n",
    "    plt.plot(\n",
    "        list(agg_w_df.index),\n",
    "        list(agg_w_df['cost']),\n",
    "        label=label,\n",
    "        marker=get_markers(label),\n",
    "        color=get_colors(label),\n",
    "        linewidth=4,\n",
    "        alpha=0.6,\n",
    "        markersize=14,\n",
    "        )\n",
    "plt.title(\"Action planning cost\\nover tower size\")\n",
    "plt.ylabel(\"Action planning cost\")\n",
    "# plt.xlabel(\"Size of tower in number of blocks\")\n",
    "plt.xlabel(\" \")\n",
    "plt.yscale('log')\n",
    "# plt.legend()\n",
    "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.savefig(\"../results/plots/tower_action_planning_scatter.pdf\",bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "for label in ['Full Subgoal Decomposition 3', 'Lookahead Scoping max size=12 lambda=0.0']:\n",
    "    ag_df = fdf[fdf['note item'] == label]\n",
    "    costs = dict(ag_df.groupby(['world item']).mean()['total_cost sum'])\n",
    "    # make a df\n",
    "    _world_cost_df = pd.DataFrame(list(costs.items()), columns=['world', 'cost'])\n",
    "    # add size to it\n",
    "    _world_cost_df['size'] = _world_cost_df['world'].apply(lambda x: tower_lengths[str(int(x))])\n",
    "    agg_w_df = _world_cost_df.groupby('size').mean()\n",
    "    jitters = (np.random.random(len(tower_lengths))-0.5)*0.25\n",
    "    # plot a scatter plot\n",
    "    plt.scatter(\n",
    "        y=list(costs.values()),\n",
    "        x=list(tower_lengths.values())+jitters,\n",
    "        c=get_colors(label),\n",
    "        # c=list(tower_lengths.values()),\n",
    "        label=label,\n",
    "        marker=get_markers(label),\n",
    "        alpha=0.6,\n",
    "        s=50,\n",
    "        )\n",
    "    # plot a line plot for average cost\n",
    "    plt.plot(\n",
    "        list(agg_w_df.index),\n",
    "        list(agg_w_df['cost']),\n",
    "        label=label,\n",
    "        marker=get_markers(label),\n",
    "        color=get_colors(label),\n",
    "        linewidth=4,\n",
    "        alpha=0.6,\n",
    "        markersize=14,\n",
    "        )\n",
    "plt.title(\"Subgoal planning cost\\nover tower size\")\n",
    "plt.ylabel(\"Subgoal planning cost\")\n",
    "plt.xlabel(\"Size of tower in number of blocks\")\n",
    "plt.xlabel(\" \")\n",
    "plt.yscale('log')\n",
    "# plt.legend()\n",
    "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.savefig(\"../results/plots/tower_subgoal_planning_scatter.pdf\",bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing between easy and hard towers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf['total_cost sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we perform a Welsh t test to see if the two groups are significantly different\n",
    "# we do this for the towers in easies vs hards\n",
    "column = \"cost sum\"\n",
    "easies_values = fdf[fdf['world item'].isin(easies)][column].values\n",
    "hards_values = fdf[fdf['world item'].isin(hards)][column].values\n",
    "result = stats.ttest_ind(hards_values, easies_values, equal_var=False)\n",
    "print(\"t: {} p: {} on {}\".format(result.statistic, result.pvalue, column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we perform a Welsh t test to see if the two groups are significantly different\n",
    "# we do this for the towers in easies vs hards\n",
    "# and across agent types\n",
    "column = \"cost sum\"\n",
    "for agent_type in fdf['agent_type item'].unique():\n",
    "    easies_values = fdf[(fdf['world item'].isin(easies)) & (fdf['agent_type item'] == agent_type)][column].values\n",
    "    hards_values = fdf[(fdf['world item'].isin(hards)) & (fdf['agent_type item'] == agent_type)][column].values\n",
    "    result = stats.ttest_ind(hards_values, easies_values, equal_var=False)\n",
    "    print(\"{}: t: {} p: {} on {}\".format(agent_type, result.statistic, result.pvalue, column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we perform a Welsh t test to see if the two groups are significantly different\n",
    "# we do this for the towers in easies vs hards\n",
    "column = \"total_cost sum\"\n",
    "easies_values = fdf[fdf['world item'].isin(easies)][column].values\n",
    "hards_values = fdf[fdf['world item'].isin(hards)][column].values\n",
    "result = stats.ttest_ind(hards_values, easies_values, equal_var=False)\n",
    "print(\"t: {} p: {} on {}\".format(result.statistic, result.pvalue, column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we perform a Welsh t test to see if the two groups are significantly different\n",
    "# we do this for the towers in easies vs hards\n",
    "# and across agent types\n",
    "column = \"total_cost sum\"\n",
    "for agent_type in fdf['agent_type item'].unique():\n",
    "    easies_values = fdf[(fdf['world item'].isin(easies)) & (fdf['agent_type item'] == agent_type)][column].values\n",
    "    hards_values = fdf[(fdf['world item'].isin(hards)) & (fdf['agent_type item'] == agent_type)][column].values\n",
    "    result = stats.ttest_ind(hards_values, easies_values, equal_var=False)\n",
    "    print(\"{}: t: {} p: {} on {}\".format(agent_type, result.statistic, result.pvalue, column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we perform a Welsh t test to see if the two groups are significantly different\n",
    "# we do this for the towers in easies vs hards\n",
    "column = \"perfect last\"\n",
    "easies_values = fdf[fdf['world item'].isin(easies)][column].values\n",
    "hards_values = fdf[fdf['world item'].isin(hards)][column].values\n",
    "result = stats.ttest_ind(hards_values, easies_values, equal_var=False)\n",
    "print(\"t: {} p: {} on {}\".format(result.statistic, result.pvalue, column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we perform a Welsh t test to see if the two groups are significantly different\n",
    "# we do this for the towers in easies vs hards\n",
    "# and across agent types\n",
    "column = \"perfect last\"\n",
    "for agent_type in fdf['agent_type item'].unique():\n",
    "    easies_values = fdf[(fdf['world item'].isin(easies)) & (fdf['agent_type item'] == agent_type)][column].values\n",
    "    hards_values = fdf[(fdf['world item'].isin(hards)) & (fdf['agent_type item'] == agent_type)][column].values\n",
    "    result = stats.ttest_ind(hards_values, easies_values, equal_var=False)\n",
    "    print(\"{}: t: {} p: {} on {}\".format(agent_type, result.statistic, result.pvalue, column))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression model\n",
    "Now we need a regression model that tests for the interaction between tower size and agent label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe for the regression\n",
    "reg_df = fdf.copy()\n",
    "# add world size\n",
    "reg_df['tower_size'] = reg_df['world item'].apply(lambda x: tower_lengths[str(int(x))])\n",
    "reg_df['world'] = reg_df['world item']\n",
    "reg_df['agent_type'] = reg_df['agent_type item']\n",
    "# log transform costs\n",
    "reg_df['log_cost'] = np.log(reg_df['cost sum'])\n",
    "reg_df['log_total_cost'] = np.log(reg_df['total_cost sum'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a linear model\n",
    "full_model = smf.ols(formula='log_total_cost ~ tower_size + agent_type + agent_type * tower_size', data=reg_df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_model.summary())\n",
    "# print the coefficients\n",
    "print(full_model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a smaller linear model\n",
    "small_model = smf.ols(formula='log_total_cost ~ tower_size + agent_type', data=reg_df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(small_model.summary())\n",
    "# print the coefficients\n",
    "print(small_model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the two models using an F test\n",
    "f_test = sm.stats.anova_lm(small_model, full_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print f test\n",
    "display(f_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(formula='log_cost ~ C(agent_type, tower_size)', data=reg_df).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===dashed line for baselines===\n",
    "note that range of lambda differs between subgoal planners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the bootstrapped dataframes over lambda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T00:26:10.592717Z",
     "iopub.status.busy": "2021-05-10T00:26:10.592468Z",
     "iopub.status.idle": "2021-05-10T02:21:49.353447Z",
     "shell.execute_reply": "2021-05-10T02:21:49.351804Z",
     "shell.execute_reply.started": "2021-05-10T00:26:10.592693Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this is going to take a while\n",
    "#which columns do we want in our bootstrapped cw_df?\n",
    "columns = ['partial_planning_cost sum',\n",
    "    'partial_planning_cost mean',\n",
    "    'partial_solution_cost sum',\n",
    "    'partial_solution_cost mean',\n",
    "    'planning_cost sum',\n",
    "    'planning_cost mean',\n",
    "    'all_sequences_planning_cost sum',\n",
    "    'all_sequences_planning_cost mean',\n",
    "    'num_subgoals_acted sum' ,\n",
    "    'num_blocks']\n",
    "\n",
    "#initialize df\n",
    "entries = []\n",
    "rows = {}\n",
    "\n",
    "#get bootstrapping entries\n",
    "for agent in wfdf['note item'].unique():\n",
    "    for c_weight in sorted(wfdf[wfdf['note item'] == agent]['c_weight item'].unique()):\n",
    "        entries.append((agent,c_weight))\n",
    "\n",
    "#let's bootstrap in parallel\n",
    "def _bootstrap_lambda(entry):\n",
    "    agent, c_weight = entry\n",
    "    new_row = {('note item',''): agent, ('c_weight item',''): c_weight}\n",
    "    for column in columns:\n",
    "        if not math.isnan(c_weight):\n",
    "            mean,CI = bootstrap(wfdf[(wfdf['note item'] == agent) & (wfdf['c_weight item'] == c_weight)],column)\n",
    "        else: #Action level doesn't have c_weight\n",
    "            mean,CI = bootstrap(wfdf[(wfdf['note item'] == agent)],column)        #insert into dictionary\n",
    "        new_row[(column,'mean')] = mean\n",
    "        new_row[(column,'CI95')] = np.array(CI)\n",
    "    return new_row\n",
    "    \n",
    "rows = p_tqdm.p_map(_bootstrap_lambda,entries)\n",
    "#create hierarchical dict\n",
    "rows = {(r[('note item','')],r[('c_weight item','')]):r for r in rows}\n",
    "    \n",
    "#create df\n",
    "cw_df = pd.DataFrame(rows).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:02:04.279995Z",
     "iopub.status.busy": "2021-05-10T10:02:04.279624Z",
     "iopub.status.idle": "2021-05-10T10:02:05.519786Z",
     "shell.execute_reply": "2021-05-10T10:02:05.517754Z",
     "shell.execute_reply.started": "2021-05-10T10:02:04.279900Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Let's store to not have to run that again\n",
    "cw_df.to_pickle(\"../results/dataframes/cw_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T02:21:49.360160Z",
     "iopub.status.busy": "2021-05-10T02:21:49.359667Z",
     "iopub.status.idle": "2021-05-10T02:39:36.309389Z",
     "shell.execute_reply": "2021-05-10T02:39:36.307887Z",
     "shell.execute_reply.started": "2021-05-10T02:21:49.360054Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this is going to take a while\n",
    "#which columns do we want in our bootstrapped cw_df_all?\n",
    "columns = ['perfect last']\n",
    "\n",
    "#initialize df\n",
    "entries = []\n",
    "rows = {}\n",
    "\n",
    "#get bootstrapping entries\n",
    "for agent in fdf['note item'].unique():\n",
    "    for c_weight in sorted(fdf[fdf['note item'] == agent]['c_weight item'].unique()):\n",
    "        entries.append((agent,c_weight))\n",
    "\n",
    "#let's bootstrap in parallel\n",
    "def _bootstrap_lambda(entry):\n",
    "    agent, c_weight = entry\n",
    "    new_row = {('note item',''): agent, ('c_weight item',''): c_weight}\n",
    "    for column in columns:\n",
    "        if not math.isnan(c_weight):\n",
    "            mean,CI = bootstrap(fdf[(fdf['note item'] == agent) & (fdf['c_weight item'] == c_weight)],column)\n",
    "        else: #Action level doesn't have c_weight\n",
    "            mean,CI = bootstrap(fdf[(fdf['note item'] == agent)],column)\n",
    "        #insert into dictionary\n",
    "        new_row[(column,'mean')] = mean\n",
    "        new_row[(column,'CI95')] = np.array(CI)\n",
    "    return new_row\n",
    "    \n",
    "rows = p_tqdm.p_map(_bootstrap_lambda,entries)\n",
    "#create hierarchical dict\n",
    "rows = {(r[('note item','')],r[('c_weight item','')]):r for r in rows}\n",
    "    \n",
    "#create df\n",
    "cw_df_all = pd.DataFrame(rows).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T10:02:30.015191Z",
     "iopub.status.busy": "2021-05-10T10:02:30.014862Z",
     "iopub.status.idle": "2021-05-10T10:02:30.027653Z",
     "shell.execute_reply": "2021-05-10T10:02:30.026768Z",
     "shell.execute_reply.started": "2021-05-10T10:02:30.015156Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Let's store to not have to run that again\n",
    "cw_df_all.to_pickle(\"../results/dataframes/cw_df_all.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T02:39:36.326713Z",
     "iopub.status.busy": "2021-05-10T02:39:36.326167Z",
     "iopub.status.idle": "2021-05-10T02:39:36.463073Z",
     "shell.execute_reply": "2021-05-10T02:39:36.461655Z",
     "shell.execute_reply.started": "2021-05-10T02:39:36.326645Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cw_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping Pearson's r helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T16:50:38.229902Z",
     "iopub.status.busy": "2021-05-10T16:50:38.229544Z",
     "iopub.status.idle": "2021-05-10T16:50:38.240271Z",
     "shell.execute_reply": "2021-05-10T16:50:38.238155Z",
     "shell.execute_reply.started": "2021-05-10T16:50:38.229868Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#bootstrapped Pearsons r helper function\n",
    "def _sample_pearsons_r_lambda(entry):\n",
    "    df,agent,column = entry\n",
    "    measurements = []\n",
    "    c_weights = sorted(df[df['note item'] == agent]['c_weight item'].unique())\n",
    "    for c_weight in c_weights:\n",
    "        # for each weight, get one mean value for the 16 structures\n",
    "        mean,_ = bootstrap(df[(df['note item'] == agent) & (df['c_weight item'] == c_weight)], \n",
    "                           column, \n",
    "                           iterations = 1,\n",
    "                          show_tqdm = False)\n",
    "        measurements.append(mean)\n",
    "    #get Pearson's r\n",
    "    r,p = stats.pearsonr(measurements,c_weights)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T23:45:17.267611Z",
     "iopub.status.busy": "2021-05-10T23:45:17.266506Z",
     "iopub.status.idle": "2021-05-10T23:45:17.285338Z",
     "shell.execute_reply": "2021-05-10T23:45:17.283718Z",
     "shell.execute_reply.started": "2021-05-10T23:45:17.267548Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#bootstrap Pearson's r\n",
    "def bootstrap_pearsons_r_lambda(df,column,iterations = 1000, C_interval = [2.5,97.5],verbose=True):\n",
    "    agents = [a for a in df['note item'].unique() if \"Scoping\" in a] #only makes sense for scoping agent\n",
    "    results = {}\n",
    "    for agent in agents:\n",
    "        print(agent)\n",
    "        # get iterations many Pearson's r\n",
    "        entries = [(df,agent,column)]*iterations\n",
    "        rs = p_tqdm.t_map(_sample_pearsons_r_lambda,entries) #just seems to hang when parallelized\n",
    "        rs = np.array(rs)\n",
    "        c_weights = sorted(df[df['note item'] == agent]['c_weight item'].unique())\n",
    "        mean = np.nanmean(rs) #we might at times get a run where the result is constant across lambda, thus nanmean\n",
    "        CI = np.nanpercentile(rs,C_interval)\n",
    "        deg_freedom = len(df[df['note item']==agent]['c_weight item'].unique()) - 2\n",
    "        rs_an = rs[~np.isnan(rs)] # get the non nan measurements\n",
    "        p_up = (sum(rs_an<0))/(len(rs_an)*2) #assuming a positive r value\n",
    "        p_down = (sum(rs_an>0))/(len(rs_an)*2) #assuming a negative r value\n",
    "        if verbose: \n",
    "            print(\"mean: \"+str(mean)+\" \\t CI: \"+str(CI) + \" \\t p positive: \"+ str(p_up) +\" \\t p negative: \"+ str(p_down)+\" \\t df: \"+str(deg_freedom))\n",
    "            n_failed = sum([math.isnan(x) for x in rs])\n",
    "            if n_failed > 0: print(n_failed, \"Pearson's r couldn't be computed\")\n",
    "        results[agent] = {'mean':mean, 'CI95': CI, 'p positive': p_up, 'p negative': p_down, 'df': deg_freedom}    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-05-09T21:28:09.845405Z",
     "iopub.status.busy": "2021-05-09T21:28:09.845005Z",
     "iopub.status.idle": "2021-05-09T21:28:17.174763Z",
     "shell.execute_reply": "2021-05-09T21:28:17.173980Z",
     "shell.execute_reply.started": "2021-05-09T21:28:09.845352Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index in cw_df.dropna().index.get_level_values(0).unique():\n",
    "    column = 'all_sequences_planning_cost sum'\n",
    "    CIs = np.array([list(x) for x in cw_df.dropna()[column]['CI95'][index]]).T\n",
    "    Xs = cw_df.dropna()[column]['mean'][index].index\n",
    "    Ys = cw_df.dropna()[column]['mean'][index]\n",
    "    Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "    plt.errorbar(Xs,\n",
    "                 Ys,\n",
    "#                  yerr=Error,\n",
    "                 label=index)\n",
    "    plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "    plt.title(\"Mean sum total planning cost over all sequences\")\n",
    "    plt.ylabel(\"States evaluated\")\n",
    "#     plt.yscale('log')\n",
    "    plt.xlabel(\"$\\lambda$\")\n",
    "    plt.legend()\n",
    "plt.show()\n",
    "\n",
    "for index in cw_df.dropna().index.get_level_values(0).unique():\n",
    "    column = 'all_sequences_planning_cost mean'\n",
    "    CIs = np.array([list(x) for x in cw_df.dropna()[column]['CI95'][index]]).T\n",
    "    Xs = cw_df.dropna()[column]['mean'][index].index\n",
    "    Ys = cw_df.dropna()[column]['mean'][index]\n",
    "    Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "    plt.errorbar(Xs,\n",
    "                 Ys,\n",
    "#                  yerr=Error,\n",
    "                 label=index)\n",
    "    plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "    plt.title(\"Mean mean total planning cost over all sequences\")\n",
    "    plt.ylabel(\"States evaluated\")\n",
    "#     plt.yscale('log')\n",
    "    plt.xlabel(\"$\\lambda$\")\n",
    "    plt.legend()\n",
    "plt.savefig(\"../results/plots/total_planning_cost_over_lambda\")\n",
    "plt.show()\n",
    "\n",
    "for index in cw_df.dropna().index.get_level_values(0).unique():\n",
    "    column = 'partial_planning_cost sum'\n",
    "    CIs = np.array([list(x) for x in cw_df.dropna()[column]['CI95'][index]]).T\n",
    "    Xs = cw_df.dropna()[column]['mean'][index].index\n",
    "    Ys = cw_df.dropna()[column]['mean'][index]\n",
    "    Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "    plt.errorbar(Xs,\n",
    "                 Ys,\n",
    "#                  yerr=Error,\n",
    "                 label=index)\n",
    "    plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "    plt.title(\"Mean sum of partial planning costs for chosen sequence\")\n",
    "    plt.ylabel(\"States evaluated\")\n",
    "#     plt.yscale('log')\n",
    "    plt.xlabel(\"$\\lambda$\")\n",
    "    plt.legend()\n",
    "plt.savefig(\"../results/plots/sum_planning_cost_chosen_seq\")\n",
    "plt.show()\n",
    "\n",
    "for index in cw_df.dropna().index.get_level_values(0).unique():\n",
    "    column = 'planning_cost sum'\n",
    "    CIs = np.array([list(x) for x in cw_df.dropna()[column]['CI95'][index]]).T\n",
    "    Xs = cw_df.dropna()[column]['mean'][index].index\n",
    "    Ys = cw_df.dropna()[column]['mean'][index]\n",
    "    Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "    plt.errorbar(Xs,\n",
    "                 Ys,\n",
    "#                  yerr=Error,\n",
    "                 label=index)\n",
    "    plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "    plt.title(\"Mean sum of planning costs for chosen sequence\")\n",
    "    plt.ylabel(\"States evaluated\")\n",
    "#     plt.yscale('log')\n",
    "    plt.xlabel(\"$\\lambda$\")\n",
    "    plt.legend()\n",
    "plt.show()\n",
    "\n",
    "for index in cw_df.dropna().index.get_level_values(0).unique():\n",
    "    column = 'partial_solution_cost mean'\n",
    "    CIs = np.array([list(x) for x in cw_df.dropna()[column]['CI95'][index]]).T\n",
    "    Xs = cw_df.dropna()[column]['mean'][index].index\n",
    "    Ys = cw_df.dropna()[column]['mean'][index]\n",
    "    Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "    plt.errorbar(Xs,\n",
    "                 Ys,\n",
    "#                  yerr=Error,\n",
    "                 label=index)\n",
    "    plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "    plt.title(\"Mean solution cost\")\n",
    "    plt.ylabel(\"States evaluated\")\n",
    "#     plt.yscale('log')\n",
    "    plt.xlabel(\"$\\lambda$\")\n",
    "    plt.legend()\n",
    "plt.show()\n",
    "\n",
    "for index in cw_df.dropna().index.get_level_values(0).unique():\n",
    "    column = 'num_blocks'\n",
    "    CIs = np.array([list(x) for x in cw_df.dropna()[column]['CI95'][index]]).T\n",
    "    Xs = cw_df.dropna()[column]['mean'][index].index\n",
    "    Ys = cw_df.dropna()[column]['mean'][index]\n",
    "    Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "    plt.errorbar(Xs,\n",
    "                 Ys,\n",
    "#                  yerr=Error,\n",
    "                 label=index)\n",
    "    plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "    plt.title(\"Number of blocks used\")\n",
    "    plt.ylabel(\"Number of blocks\")\n",
    "#     plt.yscale('log')\n",
    "    plt.xlabel(\"$\\lambda$\")\n",
    "    plt.legend()\n",
    "plt.show()\n",
    "\n",
    "for index in cw_df.dropna().index.get_level_values(0).unique():\n",
    "    column = 'num_subgoals_acted sum'\n",
    "    CIs = np.array([list(x) for x in cw_df.dropna()[column]['CI95'][index]]).T\n",
    "    Xs = cw_df.dropna()[column]['mean'][index].index\n",
    "    Ys = cw_df.dropna()[column]['mean'][index]\n",
    "    Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "    plt.errorbar(Xs,\n",
    "                 Ys,\n",
    "#                  yerr=Error,\n",
    "                 label=index)\n",
    "    plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "    plt.title(\"Mean number of subgoals\")\n",
    "    plt.ylabel(\"Number of subgoals acted out\")\n",
    "    plt.xlabel(\"$\\lambda$\")\n",
    "    plt.legend()\n",
    "plt.savefig(\"../results/plots/lambda_n_subgoals\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportion perfect reconstructionâ€”this plot is not conditioned on success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T12:46:25.100720Z",
     "iopub.status.busy": "2021-05-10T12:46:25.100479Z",
     "iopub.status.idle": "2021-05-10T12:46:25.659844Z",
     "shell.execute_reply": "2021-05-10T12:46:25.658854Z",
     "shell.execute_reply.started": "2021-05-10T12:46:25.100694Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index in cw_df_all.index.get_level_values(0).unique():\n",
    "    if \"Scoping\" not in index: continue #only plot scoping planners\n",
    "    column = 'perfect last'\n",
    "    CIs = np.array([list(x) for x in cw_df_all.dropna()[column]['CI95'][index]]).T\n",
    "    Xs = cw_df_all.dropna()[column]['mean'][index].index\n",
    "    Ys = cw_df_all.dropna()[column]['mean'][index]\n",
    "    Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "    plt.errorbar(Xs,\n",
    "                 Ys,\n",
    "#                  yerr=Error,\n",
    "                 label=index)\n",
    "    plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "    plt.title(\"Proportion perfect reconstruction\")\n",
    "    plt.ylabel(\"Proportion perfect reconstruction\")\n",
    "    plt.xlabel(\"$\\lambda$\")\n",
    "    plt.legend()\n",
    "plt.savefig(\"../results/plots/proportion_perfect_over_lambda\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper ready figures & stats ðŸ’Ž"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Action planning cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T10:23:45.328312Z",
     "iopub.status.busy": "2021-05-11T10:23:45.327750Z",
     "iopub.status.idle": "2021-05-11T10:23:48.027829Z",
     "shell.execute_reply": "2021-05-11T10:23:48.026014Z",
     "shell.execute_reply.started": "2021-05-11T10:23:45.328255Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for agent in [\"A*\",\"BFS\"]:\n",
    "    print(agent)\n",
    "    #plot scoping graph\n",
    "    index = agent1\n",
    "    column = 'partial_planning_cost sum'\n",
    "    CIs = np.array([list(x) for x in cw_df.dropna()[column]['CI95'][index]]).T\n",
    "    Xs = cw_df.dropna()[column]['mean'][index].index\n",
    "    Ys = cw_df.dropna()[column]['mean'][index]\n",
    "    Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "    plt.errorbar(Xs,\n",
    "                 Ys,\n",
    "    #                  yerr=Error,\n",
    "                 label='Scoping',\n",
    "                linewidth=4)\n",
    "    plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "        \n",
    "    #stats: linear model on scoping line over lambda\n",
    "    lm = stats.linregress(list(Xs),list(Ys))\n",
    "    df = len(Xs)+len(Ys)-2\n",
    "    t = (lm.rvalue * math.sqrt(df))/(math.sqrt(1-(lm.rvalue**2)))\n",
    "    print(lm,\"df:\",df,\"t:\",t)\n",
    "    \n",
    "    #plot lines for full\n",
    "    index = agent2\n",
    "    column = 'partial_planning_cost sum'\n",
    "    Ys = [cw_df.dropna()[column]['mean'][index]]*len(Xs)\n",
    "    CIs = np.array([list(x) for x in cw_df.dropna()[column]['CI95'][index]]).T\n",
    "    Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "    plt.errorbar(Xs,             Ys,             label='Full',linestyle = '--',linewidth=4)\n",
    "    plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "\n",
    "    #plot line for action level\n",
    "    index = agent+\"\\nAction level\"\n",
    "    column = 'partial_planning_cost sum'\n",
    "    Ys = [cw_df[column]['mean'][index].dropna()]*len(Xs)\n",
    "    CIs = np.array([list(x) for x in cw_df[column]['CI95'][index].dropna()]).T\n",
    "    Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "    plt.errorbar(Xs,             Ys,             label='Action level',linestyle = ':',linewidth=4)\n",
    "    plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "\n",
    "    plt.title(\"Action planning cost\")\n",
    "    plt.ylabel(\"States evaluated\")\n",
    "    #     plt.yscale('log')\n",
    "    plt.xlabel(\"$\\lambda$\")\n",
    "#     plt.legend()\n",
    "    plt.ylim(0,70000)\n",
    "    plt.savefig(\"../results/plots/action_planning_cost_lambda\"+agent+\".png\",bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T23:46:26.150976Z",
     "iopub.status.busy": "2021-05-10T23:46:26.150634Z",
     "iopub.status.idle": "2021-05-11T01:08:52.814233Z",
     "shell.execute_reply": "2021-05-11T01:08:52.803033Z",
     "shell.execute_reply.started": "2021-05-10T23:46:26.150945Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bootstrap_pearsons_r_lambda(wfdf,'partial_planning_cost sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:47:33.978711Z",
     "iopub.status.busy": "2021-05-10T17:47:33.977853Z",
     "iopub.status.idle": "2021-05-10T17:47:37.237690Z",
     "shell.execute_reply": "2021-05-10T17:47:37.235370Z",
     "shell.execute_reply.started": "2021-05-10T17:47:33.978608Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for agent in [\"A*\",\"BFS\"]:\n",
    "    print(agent)\n",
    "    #plot scoping graph\n",
    "    index = agent1\n",
    "    column = 'perfect last'\n",
    "    CIs = np.array([list(x) for x in cw_df_all.dropna()[column]['CI95'][index]]).T\n",
    "    Xs = cw_df_all.dropna()[column]['mean'][index].index\n",
    "    Ys = cw_df_all.dropna()[column]['mean'][index]\n",
    "    \n",
    "#     CIs = np.array([list(x) for x in cw_df_all.dropna()[column]['<lambda_0>'][index]]).T\n",
    "#     Xs = cw_df_all.dropna()[column]['mean'][index].index\n",
    "#     Ys = cw_df_all.dropna()[column]['mean'][index]\n",
    "    Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "    plt.errorbar(Xs,\n",
    "                 Ys,\n",
    "    #                  yerr=Error,\n",
    "                 label='Scoping',linewidth=4)\n",
    "    plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "    \n",
    "    #stats: linear model on scoping line over lambda\n",
    "    lm = stats.linregress(list(Xs),list(Ys))\n",
    "    df = len(Xs)+len(Ys)-2\n",
    "    t = (lm.rvalue * math.sqrt(df))/(math.sqrt(1-(lm.rvalue**2)))\n",
    "    print(lm,\"df:\",df,\"t:\",t)\n",
    "\n",
    "    #plot lines for full\n",
    "    index = agent2\n",
    "    Ys = [cw_df_all.dropna()[column]['mean'][index]]*len(Xs)\n",
    "    CIs = np.array([list(x) for x in cw_df_all.dropna()[column]['CI95'][index]]).T\n",
    "    Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "    plt.errorbar(Xs,             Ys,             label='Full',linestyle = '--',linewidth=4)\n",
    "    plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "\n",
    "    #plot line for action level\n",
    "    index = agent+\"\\nAction level\"\n",
    "    Ys = [cw_df_all[column]['mean'][index].dropna()]*len(Xs)\n",
    "    CIs = np.array([list(x) for x in cw_df_all[column]['CI95'][index].dropna()]).T\n",
    "    Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "    plt.errorbar(Xs,             Ys,             label='Action level',linestyle = ':',linewidth=4)\n",
    "    plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "\n",
    "    plt.title(\"Success\")\n",
    "    plt.ylabel(\"Rate of perfect reconstruction\")\n",
    "    #     plt.yscale('log')\n",
    "    plt.xlabel(\"$\\lambda$\")\n",
    "#     plt.legend()\n",
    "    plt.ylim(0,1.1)\n",
    "    plt.savefig(\"../results/plots/success_lambda\"+agent+\".png\",bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T01:08:52.864997Z",
     "iopub.status.busy": "2021-05-11T01:08:52.862838Z",
     "iopub.status.idle": "2021-05-11T02:35:53.430382Z",
     "shell.execute_reply": "2021-05-11T02:35:53.427911Z",
     "shell.execute_reply.started": "2021-05-11T01:08:52.864646Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bootstrap_pearsons_r_lambda(fdf,'perfect last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of blocks used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T10:19:42.553352Z",
     "iopub.status.busy": "2021-05-11T10:19:42.546215Z",
     "iopub.status.idle": "2021-05-11T10:19:44.106402Z",
     "shell.execute_reply": "2021-05-11T10:19:44.104467Z",
     "shell.execute_reply.started": "2021-05-11T10:19:42.553275Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for agent in [\"A*\",\"BFS\"]:\n",
    "    print(agent)\n",
    "    #plot scoping graph\n",
    "    index = agent1\n",
    "    column = 'num_blocks'\n",
    "    CIs = np.array([list(x) for x in cw_df.dropna()[column]['CI95'][index]]).T\n",
    "    Xs = cw_df.dropna()[column]['mean'][index].index\n",
    "    Ys = cw_df.dropna()[column]['mean'][index]\n",
    "    Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "    plt.errorbar(Xs,\n",
    "                 Ys,\n",
    "    #                  yerr=Error,\n",
    "                 label='Scoping',linewidth=4)\n",
    "    plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "    \n",
    "    #stats: linear model on scoping line over lambda\n",
    "    lm = stats.linregress(list(Xs),list(Ys))\n",
    "    df = len(Xs)+len(Ys)-2\n",
    "    t = (lm.rvalue * math.sqrt(df))/(math.sqrt(1-(lm.rvalue**2)))\n",
    "    print(lm,\"df:\",df,\"t:\",t)\n",
    "\n",
    "    #plot lines for full\n",
    "#     index = agent2\n",
    "#     Ys = [cw_df.dropna()[column]['mean'][index]]*len(Xs)\n",
    "#     CIs = np.array([list(x) for x in cw_df.dropna()[column]['CI95'][index]]).T\n",
    "#     Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "#     plt.errorbar(Xs,             Ys,             label='Full',linestyle = '--',linewidth=4)\n",
    "#     plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "\n",
    "#     #plot line for action level\n",
    "#     index = agent+\"\\nAction level\"\n",
    "#     Ys = [cw_df[column]['mean'][index].dropna()]*len(Xs)\n",
    "#     CIs = np.array([list(x) for x in cw_df[column]['CI95'][index].dropna()]).T\n",
    "#     Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "#     plt.errorbar(Xs,             Ys,             label='Action level',linestyle = ':',linewidth=4)\n",
    "#     plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "\n",
    "    plt.title(\"Number of blocks used\")\n",
    "    plt.ylabel(\"Number of blocks\")\n",
    "    #     plt.yscale('log')\n",
    "    plt.xlabel(\"$\\lambda$\")\n",
    "#     plt.legend()\n",
    "    plt.ylim(2,12)\n",
    "    plt.savefig(\"../results/plots/num_blocks_lambda\"+agent+\".png\",bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T20:39:14.177118Z",
     "iopub.status.busy": "2021-05-10T20:39:14.176774Z",
     "iopub.status.idle": "2021-05-10T21:40:03.585870Z",
     "shell.execute_reply": "2021-05-10T21:40:03.582920Z",
     "shell.execute_reply.started": "2021-05-10T20:39:14.177077Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bootstrap_pearsons_r_lambda(wfdf,'num_blocks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of subgoals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:47:46.856518Z",
     "iopub.status.busy": "2021-05-10T17:47:46.856171Z",
     "iopub.status.idle": "2021-05-10T17:47:48.752881Z",
     "shell.execute_reply": "2021-05-10T17:47:48.751835Z",
     "shell.execute_reply.started": "2021-05-10T17:47:46.856477Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for agent in [\"A*\",\"BFS\"]:\n",
    "    print(agent)\n",
    "    #plot scoping graph\n",
    "    index = agent1\n",
    "    column = 'num_subgoals_acted sum'\n",
    "    CIs = np.array([list(x) for x in cw_df.dropna()[column]['CI95'][index]]).T\n",
    "    Xs = cw_df.dropna()[column]['mean'][index].index\n",
    "    Ys = cw_df.dropna()[column]['mean'][index]\n",
    "    Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "    plt.errorbar(Xs,\n",
    "                 Ys,\n",
    "    #                  yerr=Error,\n",
    "                 label='Scoping',linewidth=4)\n",
    "    plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "    \n",
    "    #stats: linear model on scoping line over lambda\n",
    "    lm = stats.linregress(list(Xs),list(Ys))\n",
    "    df = len(Xs)+len(Ys)-2\n",
    "    t = (lm.rvalue * math.sqrt(df))/(math.sqrt(1-(lm.rvalue**2)))\n",
    "    print(lm,\"df:\",df,\"t:\",t)\n",
    "\n",
    "    #plot lines for full\n",
    "    index = agent2\n",
    "    Ys = [cw_df.dropna()[column]['mean'][index]]*len(Xs)\n",
    "    CIs = np.array([list(x) for x in cw_df.dropna()[column]['CI95'][index]]).T\n",
    "    Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "    plt.errorbar(Xs,             Ys,             label='Full',linestyle = '--',linewidth=4)\n",
    "    plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "\n",
    "    #plot line for action level\n",
    "    index = agent+\"\\nAction level\"\n",
    "    Ys = [cw_df[column]['mean'][index].dropna()]*len(Xs)\n",
    "    CIs = np.array([list(x) for x in cw_df[column]['CI95'][index].dropna()]).T\n",
    "    Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "    plt.errorbar(Xs,             Ys,             label='Action level',linestyle = ':',linewidth=4)\n",
    "    plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "\n",
    "    plt.title(\"Number of subgoals\")\n",
    "    plt.ylabel(\"Number of subgoals\")\n",
    "    #     plt.yscale('log')\n",
    "    plt.xlabel(\"$\\lambda$\")\n",
    "#     plt.legend()\n",
    "    plt.ylim(0,7)\n",
    "    plt.savefig(\"../results/plots/num_subgoals_lambda\"+agent+\".png\",bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T21:40:03.596389Z",
     "iopub.status.busy": "2021-05-10T21:40:03.595830Z",
     "iopub.status.idle": "2021-05-10T22:29:58.915406Z",
     "shell.execute_reply": "2021-05-10T22:29:58.912545Z",
     "shell.execute_reply.started": "2021-05-10T21:40:03.596312Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bootstrap_pearsons_r_lambda(wfdf,'num_subgoals_acted sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total subgoal planning cost (full planner not shown because too large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T17:47:51.151489Z",
     "iopub.status.busy": "2021-05-10T17:47:51.151194Z",
     "iopub.status.idle": "2021-05-10T17:47:52.600394Z",
     "shell.execute_reply": "2021-05-10T17:47:52.599417Z",
     "shell.execute_reply.started": "2021-05-10T17:47:51.151459Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for agent in [\"A*\",\"BFS\"]:\n",
    "    print(agent)\n",
    "    #plot scoping graph\n",
    "    index = agent1\n",
    "    column = 'all_sequences_planning_cost sum'\n",
    "    CIs = np.array([list(x) for x in cw_df.dropna()[column]['CI95'][index]]).T\n",
    "    Xs = cw_df.dropna()[column]['mean'][index].index\n",
    "    Ys = cw_df.dropna()[column]['mean'][index]\n",
    "    Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "    plt.errorbar(Xs,\n",
    "                 Ys,\n",
    "    #                  yerr=Error,\n",
    "                 label='Scoping',linewidth=4)\n",
    "    plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "\n",
    "    #stats: linear model on scoping line over lambda\n",
    "    lm = stats.linregress(list(Xs),list(Ys))\n",
    "    df = len(Xs)+len(Ys)-2\n",
    "    t = (lm.rvalue * math.sqrt(df))/(math.sqrt(1-(lm.rvalue**2)))\n",
    "    print(lm,\"df:\",df,\"t:\",t)\n",
    "    \n",
    "#     #plot lines for full\n",
    "#     index = agent2\n",
    "#     Ys = [cw_df.dropna()[column]['mean'][index]]*len(Xs)\n",
    "#     CIs = np.array([list(x) for x in cw_df.dropna()[column]['CI95'][index]]).T\n",
    "#     Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "#     plt.errorbar(Xs,             Ys,             label='Full',linestyle = '--')\n",
    "#     plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "\n",
    "#     #plot line for action level\n",
    "#     index = agent+\"\\nAction level\"\n",
    "#     Ys = [cw_df[column]['mean'][index].dropna()]*len(Xs)\n",
    "#     CIs = np.array([list(x) for x in cw_df[column]['CI95'][index].dropna()]).T\n",
    "#     Error = np.array([Ys - CIs[0],Ys + CIs[1]])\n",
    "#     plt.errorbar(Xs,             Ys,             label='Action level',linestyle = ':')\n",
    "#     plt.fill_between(Xs, CIs[0], CIs[1],alpha=0.3)\n",
    "\n",
    "    plt.title(\"Subgoal planning cost\")\n",
    "    plt.ylabel(\"Number of states evaluated\")\n",
    "#     plt.yscale('log')\n",
    "    plt.xlabel(\"$\\lambda$\")\n",
    "#     plt.legend()\n",
    "    plt.ylim(0.4e6,1.3e6)\n",
    "    plt.savefig(\"../results/plots/subgoal_planning_cost_lambda\"+agent+\".png\",bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T22:29:58.924800Z",
     "iopub.status.busy": "2021-05-10T22:29:58.924507Z",
     "iopub.status.idle": "2021-05-10T23:08:09.968459Z",
     "shell.execute_reply": "2021-05-10T23:08:09.967605Z",
     "shell.execute_reply.started": "2021-05-10T22:29:58.924728Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bootstrap_pearsons_r_lambda(wfdf,'all_sequences_planning_cost sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8a0db0c320a248546b74be3a9327a6b1846905be2e5b5893711db7bb0ee00ed"
  },
  "kernelspec": {
   "display_name": "Python [conda env:tools_bc]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
