{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block construction agent plots from experiment runner dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️**DEPRECATED! Just a repository for graphs while I port them over on an as-needed basis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and worlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-31T09:21:13.765967Z",
     "iopub.status.busy": "2020-08-31T09:21:13.740337Z",
     "iopub.status.idle": "2020-08-31T09:21:14.057329Z",
     "shell.execute_reply": "2020-08-31T09:21:14.056140Z",
     "shell.execute_reply.started": "2020-08-31T09:21:13.761982Z"
    }
   },
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-31T09:21:14.065212Z",
     "iopub.status.busy": "2020-08-31T09:21:14.064966Z",
     "iopub.status.idle": "2020-08-31T09:21:16.825041Z",
     "shell.execute_reply": "2020-08-31T09:21:16.824385Z",
     "shell.execute_reply.started": "2020-08-31T09:21:14.065187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'analysis_graphs' from '/Users/felixbinder/Cloud/Grad School/Fan Lab/Block Construction/projection_block_construction/projection_agent/analysis_graphs.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this also takes care of all the imports\n",
    "import analysis_helper\n",
    "import analysis_graphs\n",
    "from analysis_helper import *\n",
    "from analysis_graphs import *\n",
    "reload(analysis_helper)\n",
    "reload(analysis_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T08:38:04.620782Z",
     "start_time": "2020-07-11T08:38:04.607726Z"
    },
    "execution": {
     "iopub.execute_input": "2020-08-31T09:21:16.826692Z",
     "iopub.status.busy": "2020-08-31T09:21:16.826467Z",
     "iopub.status.idle": "2020-08-31T09:21:16.838072Z",
     "shell.execute_reply": "2020-08-31T09:21:16.837441Z",
     "shell.execute_reply.started": "2020-08-31T09:21:16.826659Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the dataframes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This expects the .pkls in `projection_block_construction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T08:38:23.408617Z",
     "start_time": "2020-07-11T08:38:23.406037Z"
    }
   },
   "outputs": [],
   "source": [
    "dfs = ['../breadth_to_3.pkl',\n",
    "       '../breadth_4.pkl',\n",
    "       '../MCTS.pkl',\n",
    "      '../beam_search.pkl'\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = ['breadth_to_4_sum.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = ['../beam_search.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = ['search_test.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-31T09:21:37.247794Z",
     "iopub.status.busy": "2020-08-31T09:21:37.247567Z",
     "iopub.status.idle": "2020-08-31T09:21:37.250977Z",
     "shell.execute_reply": "2020-08-31T09:21:37.250198Z",
     "shell.execute_reply.started": "2020-08-31T09:21:37.247769Z"
    }
   },
   "outputs": [],
   "source": [
    "dfs = ['exp_runner_test.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T08:47:18.277305Z",
     "start_time": "2020-07-11T08:47:15.386871Z"
    },
    "execution": {
     "iopub.execute_input": "2020-08-31T09:21:37.576496Z",
     "iopub.status.busy": "2020-08-31T09:21:37.576140Z",
     "iopub.status.idle": "2020-08-31T09:21:38.128398Z",
     "shell.execute_reply": "2020-08-31T09:21:38.127706Z",
     "shell.execute_reply.started": "2020-08-31T09:21:37.576464Z"
    }
   },
   "outputs": [],
   "source": [
    "#load all experiments as one dataframe\n",
    "df = pd.concat([pd.read_pickle(l) for l in dfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T08:47:50.928290Z",
     "start_time": "2020-07-11T08:47:50.608334Z"
    },
    "execution": {
     "iopub.execute_input": "2020-08-31T09:21:38.130185Z",
     "iopub.status.busy": "2020-08-31T09:21:38.129970Z",
     "iopub.status.idle": "2020-08-31T09:21:38.182803Z",
     "shell.execute_reply": "2020-08-31T09:21:38.182223Z",
     "shell.execute_reply.started": "2020-08-31T09:21:38.130157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_ID</th>\n",
       "      <th>agent</th>\n",
       "      <th>world</th>\n",
       "      <th>step</th>\n",
       "      <th>planning_step</th>\n",
       "      <th>states_evaluated</th>\n",
       "      <th>action</th>\n",
       "      <th>_action</th>\n",
       "      <th>action_x</th>\n",
       "      <th>action_block_width</th>\n",
       "      <th>...</th>\n",
       "      <th>heuristic</th>\n",
       "      <th>beam_width</th>\n",
       "      <th>scoring_function</th>\n",
       "      <th>horizon</th>\n",
       "      <th>scoring_type</th>\n",
       "      <th>random_seed</th>\n",
       "      <th>max_episodes</th>\n",
       "      <th>explore_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>int_struct_3 | Beam_Search_Agent beam_width: 2...</td>\n",
       "      <td>Beam_Search_Agent</td>\n",
       "      <td>int_struct_3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>[(2x4), 6]</td>\n",
       "      <td>((2x4), 6)</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>F1_stability_score</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>int_struct_3 | Beam_Search_Agent beam_width: 2...</td>\n",
       "      <td>Beam_Search_Agent</td>\n",
       "      <td>int_struct_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>[(2x4), 5]</td>\n",
       "      <td>((2x4), 5)</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>F1_stability_score</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>int_struct_3 | Beam_Search_Agent beam_width: 2...</td>\n",
       "      <td>Beam_Search_Agent</td>\n",
       "      <td>int_struct_3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>[(2x4), 0]</td>\n",
       "      <td>((2x4), 0)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>F1_stability_score</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>int_struct_3 | Beam_Search_Agent beam_width: 2...</td>\n",
       "      <td>Beam_Search_Agent</td>\n",
       "      <td>int_struct_3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>[(2x4), 0]</td>\n",
       "      <td>((2x4), 0)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>F1_stability_score</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>int_struct_3 | Beam_Search_Agent beam_width: 2...</td>\n",
       "      <td>Beam_Search_Agent</td>\n",
       "      <td>int_struct_3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>[(2x4), 2]</td>\n",
       "      <td>((2x4), 2)</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>F1_stability_score</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26774</th>\n",
       "      <td>int_struct_15 | Naive_Q_Agent heuristic: F1_st...</td>\n",
       "      <td>Naive_Q_Agent</td>\n",
       "      <td>int_struct_15</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3200</td>\n",
       "      <td>[(1x2), 6]</td>\n",
       "      <td>((1x2), 6)</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56772</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26775</th>\n",
       "      <td>int_struct_15 | Naive_Q_Agent heuristic: F1_st...</td>\n",
       "      <td>Naive_Q_Agent</td>\n",
       "      <td>int_struct_15</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>3200</td>\n",
       "      <td>[(1x2), 7]</td>\n",
       "      <td>((1x2), 7)</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56772</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26776</th>\n",
       "      <td>int_struct_15 | Naive_Q_Agent heuristic: F1_st...</td>\n",
       "      <td>Naive_Q_Agent</td>\n",
       "      <td>int_struct_15</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3200</td>\n",
       "      <td>[(1x2), 7]</td>\n",
       "      <td>((1x2), 7)</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56772</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26777</th>\n",
       "      <td>int_struct_15 | Naive_Q_Agent heuristic: F1_st...</td>\n",
       "      <td>Naive_Q_Agent</td>\n",
       "      <td>int_struct_15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>3200</td>\n",
       "      <td>[(1x2), 7]</td>\n",
       "      <td>((1x2), 7)</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56772</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26778</th>\n",
       "      <td>int_struct_15 | Naive_Q_Agent heuristic: F1_st...</td>\n",
       "      <td>Naive_Q_Agent</td>\n",
       "      <td>int_struct_15</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>3200</td>\n",
       "      <td>[(1x2), 7]</td>\n",
       "      <td>((1x2), 7)</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56772</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26779 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  run_ID              agent  \\\n",
       "0      int_struct_3 | Beam_Search_Agent beam_width: 2...  Beam_Search_Agent   \n",
       "1      int_struct_3 | Beam_Search_Agent beam_width: 2...  Beam_Search_Agent   \n",
       "2      int_struct_3 | Beam_Search_Agent beam_width: 2...  Beam_Search_Agent   \n",
       "3      int_struct_3 | Beam_Search_Agent beam_width: 2...  Beam_Search_Agent   \n",
       "4      int_struct_3 | Beam_Search_Agent beam_width: 2...  Beam_Search_Agent   \n",
       "...                                                  ...                ...   \n",
       "26774  int_struct_15 | Naive_Q_Agent heuristic: F1_st...      Naive_Q_Agent   \n",
       "26775  int_struct_15 | Naive_Q_Agent heuristic: F1_st...      Naive_Q_Agent   \n",
       "26776  int_struct_15 | Naive_Q_Agent heuristic: F1_st...      Naive_Q_Agent   \n",
       "26777  int_struct_15 | Naive_Q_Agent heuristic: F1_st...      Naive_Q_Agent   \n",
       "26778  int_struct_15 | Naive_Q_Agent heuristic: F1_st...      Naive_Q_Agent   \n",
       "\n",
       "               world step planning_step states_evaluated      action  \\\n",
       "0       int_struct_3    0             1              258  [(2x4), 6]   \n",
       "1       int_struct_3    1             1              258  [(2x4), 5]   \n",
       "2       int_struct_3    2             1              258  [(2x4), 0]   \n",
       "3       int_struct_3    3             1              258  [(2x4), 0]   \n",
       "4       int_struct_3    4             1              258  [(2x4), 2]   \n",
       "...              ...  ...           ...              ...         ...   \n",
       "26774  int_struct_15   27             1             3200  [(1x2), 6]   \n",
       "26775  int_struct_15   28             1             3200  [(1x2), 7]   \n",
       "26776  int_struct_15   29             1             3200  [(1x2), 7]   \n",
       "26777  int_struct_15   30             1             3200  [(1x2), 7]   \n",
       "26778  int_struct_15   31             1             3200  [(1x2), 7]   \n",
       "\n",
       "          _action action_x action_block_width  ...           heuristic  \\\n",
       "0      ((2x4), 6)        6                  2  ...  F1_stability_score   \n",
       "1      ((2x4), 5)        5                  2  ...  F1_stability_score   \n",
       "2      ((2x4), 0)        0                  2  ...  F1_stability_score   \n",
       "3      ((2x4), 0)        0                  2  ...  F1_stability_score   \n",
       "4      ((2x4), 2)        2                  2  ...  F1_stability_score   \n",
       "...           ...      ...                ...  ...                 ...   \n",
       "26774  ((1x2), 6)        6                  1  ...                 NaN   \n",
       "26775  ((1x2), 7)        7                  1  ...                 NaN   \n",
       "26776  ((1x2), 7)        7                  1  ...                 NaN   \n",
       "26777  ((1x2), 7)        7                  1  ...                 NaN   \n",
       "26778  ((1x2), 7)        7                  1  ...                 NaN   \n",
       "\n",
       "      beam_width scoring_function horizon scoring_type random_seed  \\\n",
       "0              2              NaN     NaN          NaN         NaN   \n",
       "1              2              NaN     NaN          NaN         NaN   \n",
       "2              2              NaN     NaN          NaN         NaN   \n",
       "3              2              NaN     NaN          NaN         NaN   \n",
       "4              2              NaN     NaN          NaN         NaN   \n",
       "...          ...              ...     ...          ...         ...   \n",
       "26774        NaN              NaN     NaN          NaN       56772   \n",
       "26775        NaN              NaN     NaN          NaN       56772   \n",
       "26776        NaN              NaN     NaN          NaN       56772   \n",
       "26777        NaN              NaN     NaN          NaN       56772   \n",
       "26778        NaN              NaN     NaN          NaN       56772   \n",
       "\n",
       "      max_episodes explore_rate learning_rate max_steps  \n",
       "0              NaN          NaN           NaN       NaN  \n",
       "1              NaN          NaN           NaN       NaN  \n",
       "2              NaN          NaN           NaN       NaN  \n",
       "3              NaN          NaN           NaN       NaN  \n",
       "4              NaN          NaN           NaN       NaN  \n",
       "...            ...          ...           ...       ...  \n",
       "26774          100          0.8             1       NaN  \n",
       "26775          100          0.8             1       NaN  \n",
       "26776          100          0.8             1       NaN  \n",
       "26777          100          0.8             1       NaN  \n",
       "26778          100          0.8             1       NaN  \n",
       "\n",
       "[26779 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T08:48:13.217094Z",
     "start_time": "2020-07-11T08:48:13.211134Z"
    }
   },
   "outputs": [],
   "source": [
    "#replace individually in py\n",
    "agents = df['agent'].unique()\n",
    "worlds = df['world'].unique()\n",
    "worlds_index = list(set([w.split('|')[0] for w in worlds]))\n",
    "#🐘\n",
    "elephant = 'int_struct_15'\n",
    "stonehenge = 'stonehenge_6_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEBUG\n",
    "wins = df[df['outcome']=='Win']\n",
    "mean_score(wins,bw.F1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-28T19:59:15.650145Z",
     "iopub.status.busy": "2020-07-28T19:59:15.649935Z",
     "iopub.status.idle": "2020-07-28T19:59:15.677999Z",
     "shell.execute_reply": "2020-07-28T19:59:15.676457Z",
     "shell.execute_reply.started": "2020-07-28T19:59:15.650124Z"
    }
   },
   "source": [
    "**Possible measures**\n",
    "Pass a selection of the table to specify.\n",
    "\n",
    "* mean_win(table)\n",
    "* mean_failure_reason(table,reason)\n",
    "* avg_steps_to_end(table)\n",
    "* mean_score(table,scoring_function)\n",
    "* mean_peak_score(table,scoring_function)\n",
    "* mean_avg_area_under_curve(table,scoring_function)\n",
    "* mean_avg_area_under_curve_to_peakF1(table,scoring_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_win\n",
    "scores = [mean_win(df[df['agent']==a]) for a in agents]    \n",
    "plt.bar(np.arange(len(scores)),scores,align='center',label=agents)\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"Proportion perfect\")\n",
    "plt.title(\"Perfect reconstruction\")\n",
    "# plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_failure_reason\n",
    "#Full\n",
    "scores = [mean_failure_reason(df[df['agent']==a],\"Full\") for a in agents]    \n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',label=\"Full\",width=0.15)\n",
    "#Unstable\n",
    "scores = [mean_failure_reason(df[df['agent']==a],\"Unstable\") for a in agents]    \n",
    "plt.bar(np.arange(len(scores))+.15,scores,align='center',label=\"Unstable\",color='green',width=0.15)\n",
    "#Outside\n",
    "scores = [mean_failure_reason(df[df['agent']==a],\"Outside\") for a in agents]    \n",
    "plt.bar(np.arange(len(scores))+.3,scores,align='center',label=\"Outside\",color='orange',width=0.15)\n",
    "#Holes\n",
    "scores = [mean_failure_reason(df[df['agent']==a],\"Holes\") for a in agents]    \n",
    "plt.bar(np.arange(len(scores))+.45,scores,align='center',label=\"Holes\",color='red',width=0.15)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Reasons for failure\")\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 avg_steps_to_end\n",
    "#all\n",
    "results = [avg_steps_to_end(df[df['agent']==a]) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [avg_steps_to_end(df[(df['agent']==a) & (df['outcome'] == 'Win')]) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [avg_steps_to_end(df[(df['agent']==a) & (df['outcome'] == 'Fail')]) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Average steps\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Average steps to end of run\")\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_score\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_score(df[df['agent']==a],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_score(df[(df['agent']==a) & (df['outcome'] == 'Win')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_score(df[(df['agent']==a) & (df['outcome'] == 'Fail')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean score\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_peak_score\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_peak_score(df[df['agent']==a],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_peak_score(df[(df['agent']==a) & (df['outcome'] == 'Win')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_peak_score(df[(df['agent']==a) & (df['outcome'] == 'Fail')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean peak score\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean peak score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_avg_area_under_curve\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_avg_area_under_curve(df[df['agent']==a],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_avg_area_under_curve(df[(df['agent']==a) & (df['outcome'] == 'Win')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_avg_area_under_curve(df[(df['agent']==a) & (df['outcome'] == 'Fail')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean average area under curve\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean average area under curve per step: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_avg_area_under_curve_to_peakF1\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[df['agent']==a],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[(df['agent']==a) & (df['outcome'] == 'Win')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[(df['agent']==a) & (df['outcome'] == 'Fail')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean average area under curve at peak F1\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean average area under curve per step at peak F1 score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T08:48:41.479807Z",
     "start_time": "2020-07-11T08:48:41.423434Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#wins over agent\n",
    "#output can be pasted into numbers with space as seperator\n",
    "for agent in agents:\n",
    "    wins = 0\n",
    "    total = 0\n",
    "    for o in df[df['agent']==agent]['outcome']:\n",
    "        if o == 'Win':\n",
    "            wins+=1\n",
    "        total += 1\n",
    "    print(wins,'/',total,str(round(100*wins/total,2))+'%',agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average number of steps per agent for failure and success\n",
    "for agent in agents:\n",
    "    win_lengths = []\n",
    "    failure_lengths = []\n",
    "    for i,row in df[df['agent']==agent].iterrows():\n",
    "        num_steps = len(get_blockmaps(row['run'])) # get number of steps\n",
    "        if row['outcome'] == 'Win':\n",
    "            win_lengths.append(num_steps)\n",
    "        if row['outcome'] == 'Fail':\n",
    "            failure_lengths.append(num_steps)\n",
    "    print(agent)\n",
    "    print(len(win_lengths),\"wins with avg length\",sum(win_lengths)/len(win_lengths))\n",
    "    print(len(failure_lengths),\"wins with avg length\",sum(failure_lengths)/len(failure_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#failure reasons per agent\n",
    "for agent in agents:\n",
    "    failure_reasons = {}\n",
    "    for run in df[df['agent'] == agent]['run']:\n",
    "        status, reason = get_final_status(run)\n",
    "        if reason in failure_reasons.keys():\n",
    "            failure_reasons[reason] += 1\n",
    "        else:\n",
    "            failure_reasons[reason] = 1\n",
    "    print(agent,'\\n',failure_reasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T09:51:44.185400Z",
     "start_time": "2020-07-11T09:50:33.664045Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot F1 over time for agent\n",
    "for agent in agents:\n",
    "    plt.clf() #clear the plot\n",
    "    for run in df[df['agent']==agent]['run']:\n",
    "        plt.plot(run['F1 score'].to_list(),linewidth=0.3)\n",
    "    plt.title(agent)\n",
    "    plt.xlim([0,20])\n",
    "    plt.ylim([0,1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T09:56:01.966692Z",
     "start_time": "2020-07-11T09:54:48.318673Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot blocksize over time for agent\n",
    "for agent in agents:\n",
    "    plt.clf() #clear the plot\n",
    "    for run in df[df['agent']==agent]['run']:\n",
    "        blocks_obj = run[run.notnull()['chosen action']]['chosen action'].to_list()\n",
    "        size = [float(a)*float(b) for a,b in [b[0][0][1:-1].split('x') for b in blocks_obj]]\n",
    "        plt.plot(size,linewidth=0.3)\n",
    "    plt.title(agent)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T09:56:01.966692Z",
     "start_time": "2020-07-11T09:54:48.318673Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot avg blocksize over time for agent\n",
    "for agent in agents:\n",
    "    plt.clf() #clear the plot\n",
    "    for run in df[df['agent']==agent]['run']:\n",
    "        blocks_obj = run[run.notnull()['chosen action']]['chosen action'].to_list()\n",
    "        size = [float(a)*float(b) for a,b in [b[0][0][1:-1].split('x') for b in blocks_obj]]\n",
    "        plt.plot(size,linewidth=0.3)\n",
    "    plt.title(\"Average blocksize for \"+agent)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per world\n",
    "Makes more sense to selectively run worlds in the section further below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worlds = df['world'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-29T09:35:50.461450Z",
     "iopub.status.busy": "2020-07-29T09:35:50.461237Z",
     "iopub.status.idle": "2020-07-29T09:35:50.464486Z",
     "shell.execute_reply": "2020-07-29T09:35:50.463453Z",
     "shell.execute_reply.started": "2020-07-29T09:35:50.461428Z"
    }
   },
   "source": [
    "### Bar graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_win\n",
    "scores = [mean_win(df[df['world']==w]) for w in worlds]    \n",
    "plt.bar(np.arange(len(scores)),scores,align='center')\n",
    "plt.xticks(np.arange(len(scores)),worlds,rotation=45,ha='right')\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"Proportion perfect\")\n",
    "plt.title(\"Perfect reconstruction\")\n",
    "# plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_failure_reason\n",
    "#Full\n",
    "scores = [mean_failure_reason(df[df['world']==w],\"Full\") for w in worlds]    \n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',label=\"Full\",width=0.15)\n",
    "#Unstable\n",
    "scores = [mean_failure_reason(df[df['world']==w],\"Unstable\") for w in worlds]    \n",
    "plt.bar(np.arange(len(scores))+.15,scores,align='center',label=\"Unstable\",color='green',width=0.15)\n",
    "#Outside\n",
    "scores = [mean_failure_reason(df[df['world']==w],\"Outside\") for w in worlds]    \n",
    "plt.bar(np.arange(len(scores))+.3,scores,align='center',label=\"Outside\",color='orange',width=0.15)\n",
    "#Holes\n",
    "scores = [mean_failure_reason(df[df['world']==w],\"Holes\") for w in worlds]    \n",
    "plt.bar(np.arange(len(scores))+.45,scores,align='center',label=\"Holes\",color='red',width=0.15)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Reasons for failure\")\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 avg_steps_to_end\n",
    "#all\n",
    "results = [avg_steps_to_end(df[df['world']==w]) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [avg_steps_to_end(df[(df['world']==w) & (df['outcome'] == 'Win')]) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [avg_steps_to_end(df[(df['world']==w) & (df['outcome'] == 'Fail')]) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Average steps\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Average steps to end of run\")\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_score\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_score(df[df['world']==w],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_score(df[(df['world']==w) & (df['outcome'] == 'Win')],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_score(df[(df['world']==w) & (df['outcome'] == 'Fail')],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean score\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_peak_score\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_peak_score(df[df['world']==w],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_peak_score(df[(df['world']==w) & (df['outcome'] == 'Win')],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_peak_score(df[(df['world']==w) & (df['outcome'] == 'Fail')],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean peak score\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean peak score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_avg_area_under_curve\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_avg_area_under_curve(df[df['world']==w],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_avg_area_under_curve(df[(df['world']==w) & (df['outcome'] == 'Win')],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_avg_area_under_curve(df[(df['world']==w) & (df['outcome'] == 'Fail')],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean average area under curve\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean average area under curve per step: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_avg_area_under_curve_to_peakF1\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[df['world']==w],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[(df['world']==w) & (df['outcome'] == 'Win')],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[(df['world']==w) & (df['outcome'] == 'Fail')],scoring_function) for w in worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean average area under curve at peak F1\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean average area under curve per step at peak F1 score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T09:29:57.306706Z",
     "start_time": "2020-07-11T09:29:56.830838Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#wins over world\n",
    "for world in worlds_index:\n",
    "    wins = 0\n",
    "    total = 0\n",
    "    for o in df[df['world'].str.contains(world)]['outcome']:\n",
    "        if o == 'Win':\n",
    "            wins+=1\n",
    "        total += 1\n",
    "    print(wins,'/',total,str(round(100*wins/total,2))+'%',world)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-29T11:06:44.822756Z",
     "iopub.status.busy": "2020-07-29T11:06:44.822545Z",
     "iopub.status.idle": "2020-07-29T11:06:44.825629Z",
     "shell.execute_reply": "2020-07-29T11:06:44.824628Z",
     "shell.execute_reply.started": "2020-07-29T11:06:44.822735Z"
    }
   },
   "source": [
    "### Plots & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T15:03:35.753580Z",
     "start_time": "2020-06-23T15:03:29.925935Z"
    }
   },
   "outputs": [],
   "source": [
    "#images of worlds\n",
    "for i,world in enumerate(bw_worlds.values()):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.imshow(world.silhouette)\n",
    "    plt.xlabel(i)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T22:43:31.682478Z",
     "start_time": "2020-06-08T22:29:10.228756Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CAUTION, lots of data\n",
    "#plot all blockmaps\n",
    "for agent in agents:\n",
    "    plt.clf() #clear the plot\n",
    "    for run in df[df['agent']==agent]['run']:\n",
    "        bm_obj = run[run.notnull()['blockmap']]['blockmap'].tail(1)\n",
    "        blockmap = np.array(bm_obj.to_list())[0,0,::] #convert object back to np and take the wrappers off\n",
    "        plt.pcolormesh(blockmap[::-1], cmap='hot_r',vmin=0)\n",
    "        plt.title(agent)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T15:03:06.934620Z",
     "start_time": "2020-06-23T15:03:04.984902Z"
    }
   },
   "outputs": [],
   "source": [
    "#win ratio for world\n",
    "for world in worlds_index:\n",
    "    won = 0\n",
    "    total = 0\n",
    "    for index,outcome in df[(df['world'].str.contains(world))][['outcome']].iterrows():\n",
    "        if outcome[0] == 'Win': won += 1\n",
    "        total += 1\n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.imshow(bw_worlds[world.split('|')[0]].silhouette)\n",
    "    plt.show()\n",
    "    print(won,'/',total,'->',(won/total)*100,'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per world & agent\n",
    "Creates **a lot** of bars, better to use chosen world section.\n",
    "\n",
    "More plots in chosen world section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents_worlds = [(a,w) for a in agents for w in worlds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_win\n",
    "scores = [mean_win(df[(df['world']==w) & (df['agent']==a)]) for a,w in agents_worlds]    \n",
    "plt.bar(np.arange(len(scores)),scores,align='center')\n",
    "plt.xticks(np.arange(len(scores)),agents_worlds,rotation=45,ha='right')\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"Proportion perfect\")\n",
    "plt.title(\"Perfect reconstruction\")\n",
    "# plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_failure_reason\n",
    "#Full\n",
    "scores = [mean_failure_reason(df[(df['world']==w) & (df['agent']==a)],\"Full\") for a,w in agents_worlds]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',label=\"Full\",width=0.15)\n",
    "#Unstable\n",
    "scores = [mean_failure_reason(df[(df['world']==w) & (df['agent']==a)],\"Unstable\") for a,w in agents_worlds]\n",
    "plt.bar(np.arange(len(scores))+.15,scores,align='center',label=\"Unstable\",color='green',width=0.15)\n",
    "#Outside\n",
    "scores = [mean_failure_reason(df[(df['world']==w) & (df['agent']==a)],\"Outside\") for a,w in agents_worlds]\n",
    "plt.bar(np.arange(len(scores))+.3,scores,align='center',label=\"Outside\",color='orange',width=0.15)\n",
    "#Holes\n",
    "scores = [mean_failure_reason(df[(df['world']==w) & (df['agent']==a)],\"Holes\") for a,w in agents_worlds]\n",
    "plt.bar(np.arange(len(scores))+.45,scores,align='center',label=\"Holes\",color='red',width=0.15)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents_worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Reasons for failure\")\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 avg_steps_to_end\n",
    "#all\n",
    "results = [avg_steps_to_end(df[(df['world']==w) & (df['agent']==a)]) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [avg_steps_to_end(df[(df['world']==w) & (df['agent']==a)  & (df['outcome'] == 'Win')]) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [avg_steps_to_end(df[(df['world']==w) & (df['agent']==a)  & (df['outcome'] == 'Fail')]) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents_worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Average steps\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Average steps to end of run\")\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_score\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_score(df[(df['world']==w) & (df['agent']==a)],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_score(df[(df['world']==w) & (df['agent']==a)  & (df['outcome'] == 'Win')],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_score(df[(df['world']==w) & (df['agent']==a)  & (df['outcome'] == 'Fail')],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents_worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean score\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_peak_score\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_peak_score(df[(df['world']==w) & (df['agent']==a)],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_peak_score(df[(df['world']==w) & (df['agent']==a)  & (df['outcome'] == 'Win')],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_peak_score(df[(df['world']==w) & (df['agent']==a)  & (df['outcome'] == 'Fail')],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents_worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean peak score\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean peak score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_avg_area_under_curve\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_avg_area_under_curve(df[(df['world']==w) & (df['agent']==a)],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_avg_area_under_curve(df[(df['world']==w) & (df['agent']==a)  & (df['outcome'] == 'Win')],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_avg_area_under_curve(df[(df['world']==w) & (df['agent']==a)  & (df['outcome'] == 'Fail')],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents_worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean average area under curve\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean average area under curve per step: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_avg_area_under_curve_to_peakF1\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[(df['world']==w) & (df['agent']==a)],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[(df['world']==w) & (df['agent']==a)  & (df['outcome'] == 'Win')],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[(df['world']==w) & (df['agent']==a)  & (df['outcome'] == 'Fail')],scoring_function) for a,w in agents_worlds]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents_worlds,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean average area under curve at peak F1\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean average area under curve per step at peak F1 score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T09:58:43.708284Z",
     "start_time": "2020-07-11T09:57:52.621749Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#block size over worlds and agents\n",
    "#crashes, but it's not important anyway\n",
    "for world in worlds_index:\n",
    "    dfw = df[df['world'].str.contains(world)]\n",
    "    for agent in agents:\n",
    "        plt.clf() #clear the plot\n",
    "        for run in dfw[dfw['agent']==agent]['run']:\n",
    "            blocks_obj = run[run.notnull()['chosen action']]['chosen action'].to_list()\n",
    "            size = [float(a)*float(b) for a,b in [b[0][0][1:-1].split('x') for b in blocks_obj]]\n",
    "            plt.plot(size)\n",
    "        plt.title(agent+' on world '+world)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-11T10:01:33.608Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#over worlds and agents: F1 score\n",
    "for world in worlds_index:\n",
    "    dfw = df[df['world'].str.contains(world)]\n",
    "    bw_world = bw_worlds[world.split('|')[0]]\n",
    "    for agent in agents:\n",
    "        plt.clf() #clear the plot\n",
    "        for run in dfw[dfw['agent']==agent]['run']:\n",
    "            blocks_obj = run[run.notnull()['chosen action']]['chosen action'].to_list()\n",
    "            bm_obj = run[run.notnull()['blockmap']]['blockmap'].tail(1)\n",
    "            blockmap = np.array(bm_obj.to_list())[0,0,::] #convert object back to np and take the wrappers off\n",
    "            scores = []\n",
    "            for move in range(np.max(blockmap)): #for every move\n",
    "                _bmm = blockmap * (blockmap <= move)\n",
    "                _state = State(bw_world,_bmm)\n",
    "                score = bw.F1score(_state)\n",
    "                scores.append(score)\n",
    "            plt.plot(scores)\n",
    "        plt.title(agent+' on world '+world)\n",
    "        plt.xlim([0,20])\n",
    "        plt.ylim([0,1])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T23:23:23.748590Z",
     "start_time": "2020-06-08T23:23:23.131345Z"
    }
   },
   "outputs": [],
   "source": [
    "#over worlds and agents: precision score\n",
    "for world in worlds:\n",
    "    dfw = df[df['world']==world]\n",
    "    bw_world = bw_worlds[world]\n",
    "    for agent in agents:\n",
    "        plt.clf() #clear the plot\n",
    "        for run in dfw[dfw['agent']==agent]['run']:\n",
    "            blocks_obj = run[run.notnull()['chosen action']]['chosen action'].to_list()\n",
    "            bm_obj = run[run.notnull()['blockmap']]['blockmap'].tail(1)\n",
    "            blockmap = np.array(bm_obj.to_list())[0,0,::] #convert object back to np and take the wrappers off\n",
    "            for move in range(np.max(blockmap)): #for every move\n",
    "                _bmm = blockmap * (blockmap <= move)\n",
    "                _state = State(bw_worlds[world.split('|')[0]],_bmm)\n",
    "                score = bw.precision(_state)\n",
    "                scores.append(score)\n",
    "            plt.plot(scores)\n",
    "        plt.title(agent+' on world '+world)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T15:03:06.934620Z",
     "start_time": "2020-06-23T15:03:04.984902Z"
    }
   },
   "outputs": [],
   "source": [
    "#win ratio for world & agent\n",
    "for world in worlds_index:\n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.imshow(bw_worlds[world.split('|')[0]].silhouette)\n",
    "    plt.show()\n",
    "    for agent in agents:\n",
    "        won = 0\n",
    "        total = 0\n",
    "        for index,outcome in df[(df['world'].str.contains(world)) & (df['agent'] == agent)][['outcome']].iterrows():\n",
    "            if outcome[0] == 'Win': won += 1\n",
    "            total += 1\n",
    "        print(agent,':',won,'/',total,'->',(won/total)*100,'%')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-11T15:30:51.436900Z",
     "iopub.status.busy": "2020-07-11T15:30:51.436681Z",
     "iopub.status.idle": "2020-07-11T15:30:51.451438Z",
     "shell.execute_reply": "2020-07-11T15:30:51.450205Z",
     "shell.execute_reply.started": "2020-07-11T15:30:51.436879Z"
    }
   },
   "source": [
    "## Per horizon\n",
    "### Plots\n",
    "Generally, it makes more sense to narrow the agents down to only have differences in types between horizon rather than integrate between horizon and then run per agent plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T23:23:48.433436Z",
     "start_time": "2020-06-08T23:23:25.827044Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot F1 over time for horizon\n",
    "for horizon in ['1','2','3']:\n",
    "    plt.clf() #clear the plot\n",
    "    for row in df[df['agent'].str.contains(\"horizon: \"+horizon)][['run','world']].iterrows():\n",
    "        index, row = row\n",
    "        run,world = row\n",
    "        blocks_obj = run[run.notnull()['chosen action']]['chosen action'].to_list()\n",
    "        bm_obj = run[run.notnull()['blockmap']]['blockmap'].tail(1)\n",
    "        blockmap = np.array(bm_obj.to_list())[0,0,::] #convert object back to np and take the wrappers off\n",
    "        scores =[]\n",
    "        for move in range(np.max(blockmap)): #for every move\n",
    "            _bmm = blockmap * (blockmap <= move)\n",
    "            _state = State(bw_worlds[world.split('|')[0]],_bmm)\n",
    "            score = bw.F1score(_state)\n",
    "            scores.append(score)\n",
    "        plt.plot(scores,linewidth=0.1)\n",
    "    plt.title(horizon)\n",
    "    plt.ylabel('F1 score')\n",
    "    plt.xlabel('Step')\n",
    "    plt.xlim(0,32)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T15:03:35.753580Z",
     "start_time": "2020-06-23T15:03:29.925935Z"
    }
   },
   "outputs": [],
   "source": [
    "#images of worlds\n",
    "for i,world in enumerate(bw_worlds.values()):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.subplot(3,4,i+1)\n",
    "    plt.imshow(world.silhouette)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per chosen world\n",
    "For comparisions between agents on a particular world. Most plots make the most sense here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T17:09:15.141655Z",
     "start_time": "2020-06-24T17:09:15.138260Z"
    }
   },
   "outputs": [],
   "source": [
    "# chosen_world = elephant\n",
    "chosen_world = 'stonehenge_6_4'\n",
    "chosen_world_obj = bw_worlds[chosen_world]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-29T11:38:22.310198Z",
     "iopub.status.busy": "2020-07-29T11:38:22.309938Z",
     "iopub.status.idle": "2020-07-29T11:38:22.313030Z",
     "shell.execute_reply": "2020-07-29T11:38:22.312349Z",
     "shell.execute_reply.started": "2020-07-29T11:38:22.310171Z"
    }
   },
   "source": [
    "### Bar graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_win\n",
    "scores = [mean_win(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)]) for a in agents]    \n",
    "plt.bar(np.arange(len(scores)),scores,align='center')\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"Proportion perfect\")\n",
    "plt.title(\"Perfect reconstruction\")\n",
    "# plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_failure_reason\n",
    "#Full\n",
    "scores = [mean_failure_reason(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)],\"Full\") for a in agents]    \n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',label=\"Full\",width=0.15)\n",
    "#Unstable\n",
    "scores = [mean_failure_reason(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)],\"Unstable\") for a in agents]    \n",
    "plt.bar(np.arange(len(scores))+.15,scores,align='center',label=\"Unstable\",color='green',width=0.15)\n",
    "#Outside\n",
    "scores = [mean_failure_reason(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)],\"Outside\") for a in agents]    \n",
    "plt.bar(np.arange(len(scores))+.3,scores,align='center',label=\"Outside\",color='orange',width=0.15)\n",
    "#Holes\n",
    "scores = [mean_failure_reason(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)],\"Holes\") for a in agents]    \n",
    "plt.bar(np.arange(len(scores))+.45,scores,align='center',label=\"Holes\",color='red',width=0.15)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Reasons for failure\")\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 avg_steps_to_end\n",
    "#all\n",
    "results = [avg_steps_to_end(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)]) for a in agents]\n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [avg_steps_to_end(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)  & (df['outcome'] == 'Win')]) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [avg_steps_to_end(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)  & (df['outcome'] == 'Fail')]) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Average steps\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Average steps to end of run\")\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_score\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_score(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_score(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)  & (df['outcome'] == 'Win')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_score(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)  & (df['outcome'] == 'Fail')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean score\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_peak_score\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_peak_score(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_peak_score(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)  & (df['outcome'] == 'Win')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_peak_score(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)  & (df['outcome'] == 'Fail')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean peak score\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean peak score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_avg_area_under_curve\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_avg_area_under_curve(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_avg_area_under_curve(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)  & (df['outcome'] == 'Win')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_avg_area_under_curve(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)  & (df['outcome'] == 'Fail')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean average area under curve\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean average area under curve per step: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#📊 mean_avg_area_under_curve_to_peakF1\n",
    "scoring_function = bw.F1score\n",
    "#all\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+0,scores,align='center',yerr=stds,label=\"All\",width=0.2)\n",
    "#win\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)  & (df['outcome'] == 'Win')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.2,scores,align='center',yerr=stds,label=\"Win\",color='green',width=0.2)\n",
    "#fail\n",
    "results = [mean_avg_area_under_curve_to_peakF1(df[(df['world'].str.contains(chosen_world)) & (df['agent']==a)  & (df['outcome'] == 'Fail')],scoring_function) for a in agents]    \n",
    "scores = [score for score,std in results]\n",
    "stds = [std for score,std in results]\n",
    "plt.bar(np.arange(len(scores))+.4,scores,align='center',yerr=stds,label=\"Fail\",color='orange',width=0.2)\n",
    "\n",
    "plt.xticks(np.arange(len(scores)),agents,rotation=45,ha='right')\n",
    "plt.ylabel(\"Mean average area under curve at peak F1\")\n",
    "plt.ylim(0)\n",
    "plt.title(\"Mean average area under curve per step at peak F1 score: \"+scoring_function.__name__)\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-29T11:38:33.101620Z",
     "iopub.status.busy": "2020-07-29T11:38:33.101411Z",
     "iopub.status.idle": "2020-07-29T11:38:33.105058Z",
     "shell.execute_reply": "2020-07-29T11:38:33.104091Z",
     "shell.execute_reply.started": "2020-07-29T11:38:33.101598Z"
    }
   },
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average number of steps per agent on chosen world for failure and success\n",
    "for agent in agents:\n",
    "    win_lengths = []\n",
    "    failure_lengths = []\n",
    "    for i,row in df[(df['agent']==agent) & (df['world'].str.contains(chosen_world))].iterrows():\n",
    "        num_steps = len(get_blockmaps(row['run'])) # get number of steps\n",
    "        if row['outcome'] == 'Win':\n",
    "            win_lengths.append(num_steps)\n",
    "        if row['outcome'] == 'Fail':\n",
    "            failure_lengths.append(num_steps)\n",
    "    print(agent)\n",
    "    print(len(win_lengths),\"wins with avg length\",sum(win_lengths)/(len(win_lengths)+0.0001))\n",
    "    print(len(failure_lengths),\"failures with avg length\",sum(failure_lengths)/(len(failure_lengths)+0.0001))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over agents in one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T15:02:22.676359Z",
     "start_time": "2020-06-24T15:02:22.506188Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#wins over agent for chosen world\n",
    "for agent in agents:\n",
    "    wins = 0\n",
    "    total = 0\n",
    "    for o in df[(df['agent']==agent) & (df['world'].str.contains(chosen_world))]['outcome']:\n",
    "        if o == 'Win':\n",
    "            wins+=1\n",
    "        total += 1\n",
    "    print(wins,'/',total,str(round(100*wins/total,2))+'%',agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot all F1 over time for chosen world and over agents colored by success\n",
    "runs = get_BFS_runs(_world_indexes=[chosen_world]) #get runs\n",
    "_agents = runs['agent'].unique() #get agents\n",
    "for _agent in _agents: #plot per agent\n",
    "    a_runs = runs[runs['agent'] == _agent]\n",
    "    for i,row in a_runs.iterrows(): #for each run of the agent\n",
    "        blockmaps = get_blockmaps(row['run']) #get sequence of blockmaps\n",
    "        fin_status,fin_reason = get_final_status(row['run'])\n",
    "        #calculate the score for each blockmap\n",
    "        scores = []\n",
    "        for bm in blockmaps:\n",
    "            #make a State to score\n",
    "            state = State(chosen_world_obj,bm)\n",
    "            score = bw.F1score(state)\n",
    "            scores.append(score)\n",
    "        #plot\n",
    "        plt.plot(scores,linewidth=0.3,c='green' if fin_status == 'Win' else 'red')\n",
    "        plt.xlim(0,xlim)\n",
    "        plt.ylim(0,1)\n",
    "    plt.title('F1 for '+_agent)\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot all F1 over time for chosen world and over agents—endaligned\n",
    "# runs = get_BFS_runs(_world_indexes=[chosen_world]) #get runs\n",
    "_agents = df['agent'].unique() #get agents\n",
    "for _agent in _agents: #plot per agent\n",
    "    a_runs = df[df['agent'] == _agent & df['world']==chosen_world]\n",
    "    for i,row in a_runs.iterrows(): #for each run of the agent\n",
    "        blockmaps = get_blockmaps(row['run']) #get sequence of blockmaps\n",
    "        fin_status,fin_reason = get_final_status(row['run'])\n",
    "        #calculate the score for each blockmap\n",
    "        scores = []\n",
    "        for bm in blockmaps:\n",
    "            #make a State to score\n",
    "            state = State(chosen_world_obj,bm)\n",
    "            score = bw.F1score(state)\n",
    "            scores.append(score)\n",
    "        #plot\n",
    "        plt.plot(scores[::-1],linewidth=0.3,c='green' if fin_status == 'Win' else 'red')\n",
    "        plt.xlim(xlim,0)\n",
    "        plt.ylim(0,1)\n",
    "    plt.title('F1 for '+_agent)\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot mean F1,std over time for chosen world and over agents in one plot (with continuation)\n",
    "#change scoring function to precision, recall,...\n",
    "runs = get_BFS_runs(_world_indexes=[chosen_world]) #get runs\n",
    "_agents = runs['agent'].unique() #get agents\n",
    "for _agent in _agents: #plot per agent\n",
    "    a_runs = runs[runs['agent'] == _agent]\n",
    "    run_scores = []\n",
    "    for i,row in a_runs.iterrows(): #for each run of the agent\n",
    "        blockmaps = get_blockmaps(row['run']) #get sequence of blockmaps\n",
    "        #calculate the score for each blockmap\n",
    "        scores = []\n",
    "        for bm in blockmaps:\n",
    "            #make a State to score\n",
    "            state = State(chosen_world_obj,bm)\n",
    "            score = bw.F1score(state)\n",
    "            scores.append(score)\n",
    "        #append (pad) score with last value to xlim as a way of handling the early termination of trials\n",
    "        scores = [scores[i] if i < len(scores) else scores[-1] for i in range(xlim+1)]\n",
    "        run_scores.append(scores)\n",
    "    #avg,std\n",
    "    avgs = np.mean(run_scores,axis=0)\n",
    "    stds = np.std(run_scores,axis=0)\n",
    "    #plot\n",
    "#     plt.plot(range(len(avgs)),avgs)\n",
    "    plt.errorbar(range(len(avgs)),avgs,stds,label=_agent)\n",
    "    plt.xlim(0,xlim)\n",
    "    plt.ylim(0,1)\n",
    "plt.title('Mean F1')\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot avg blocksize over time for agent in chosen world\n",
    "#mind that most of the later ones are NaNs!\n",
    "for agent in agents:\n",
    "    sizes_runs = []\n",
    "    for run in df[(df['agent']==agent) & df['world'].str.contains(chosen_world)]['run']:\n",
    "        blocks_obj = run[run.notnull()['chosen action']]['chosen action'].to_list()\n",
    "        sizes_run = [float(a)*float(b) for a,b in [b[0][0][1:-1].split('x') for b in blocks_obj]]\n",
    "        sizes_runs.append(sizes_run)\n",
    "    len_seq = max([len(s) for s in sizes_runs]) #length of the longest sequence\n",
    "    runs_arr = np.full([len(sizes_runs),len_seq],np.nan)\n",
    "    #fill the array\n",
    "    for i,sizes_run in enumerate(sizes_runs):\n",
    "        runs_arr[i,0:len(sizes_run)] = sizes_run\n",
    "    #get stats\n",
    "    means = np.nanmean(runs_arr,axis=0)\n",
    "    stds = np.nanstd(runs_arr,axis=0)\n",
    "    plt.errorbar(range(len(means)),means,stds,label=agent)\n",
    "plt.title(\"Average blocksize\")\n",
    "plt.legend(bbox_to_anchor=(1.04,0), loc=\"lower left\", borderaxespad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run selectors\n",
    "Helper functions to generate dataframes according to specifications of the agent. \n",
    "- [ ] Move to analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BFS_runs(_sparses = ['False','True'],\n",
    "                 _horizons = ['1','2','3','4','5'],\n",
    "                 _scoring_functions=['random_scoring',\n",
    "                            'silhouette_hole_score','silhouette_score','F1score'],\n",
    "                 _scorings = ['Sum','Average','Random','Final state'],\n",
    "                 _outcomes = ['Fail','Ongoing','Win'],\n",
    "                 _reasons = None,\n",
    "                 _world_indexes=None):\n",
    "    \"\"\"Returns all rows of the dataframe that fit the list of parameters. \n",
    "    Parameters must be passed as lists.\n",
    "    All reasons are ['None','Full','Holes','Unstable']\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    if _world_indexes is None:\n",
    "        _world_indexes = worlds_index\n",
    "    for world_index in _world_indexes:\n",
    "        dfw = df[df['world'].str.contains(world_index)] #get the lines of the corresponding world\n",
    "        for horizon in _horizons:\n",
    "            for scoring_function in _scoring_functions:\n",
    "                for sparse in _sparses:\n",
    "                    for scoring in _scorings:\n",
    "                        filter = \"type: BFS_Agent scoring: \"+scoring_function+\" horizon: \"+horizon+\" scoring: \"+scoring +\" sparse\\?: \"+sparse\n",
    "                        dfwa = dfw[dfw['agent'].str.contains(filter)]\n",
    "                        for outcome in _outcomes:\n",
    "                            rows.append(dfwa[dfwa['outcome'] == outcome])\n",
    "    dfc = pd.concat(rows)\n",
    "    if _reasons is not None: #if we want to know the reason of failure\n",
    "        reasons = [get_final_status(run)[1] for run in dfc['run']]\n",
    "        filter = [True if reason in _reasons else False for reason in reasons]\n",
    "        dfc = dfc[filter]\n",
    "    return dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT TESTED YET\n",
    "def get_MCTS_runs(_budgets = ['10','100','1000','10000','100000'],\n",
    "                 _outcomes = ['Fail','Ongoing','Win'],\n",
    "                 _reasons = None,\n",
    "                 _world_indexes=None):\n",
    "    \"\"\"Returns all rows of the dataframe that fit the list of parameters. \n",
    "    Parameters must be passed as lists.\n",
    "    All reasons are ['None','Full','Holes','Unstable']\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    if _world_indexes is None:\n",
    "        _world_indexes = worlds_index\n",
    "    for world_index in _world_indexes:\n",
    "        dfw = df[df['world'].str.contains(world_index)] #get the lines of the corresponding world\n",
    "        for budget in _budgets:\n",
    "            filter = \"type: MCTS_Agent horizon: \"+horizon+'\\Z'\n",
    "            dfwa = dfw[dfw['agent'].str.contains(filter)]\n",
    "            for outcome in _outcomes:\n",
    "                rows.append(dfwa[dfwa['outcome'] == outcome])\n",
    "    dfc = pd.concat(rows)\n",
    "    if _reasons is not None: #if we want to know the reason of failure\n",
    "        reasons = [get_final_status(run)[1] for run in dfc['run']]\n",
    "        filter = [True if reason in _reasons else False for reason in reasons]\n",
    "        dfc = dfc[filter]\n",
    "    return dfc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('projection_blocks': conda)",
   "language": "python",
   "name": "python38264bitprojectionblocksconda86e74604eaa74b86af1676acbf4e26f9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "notify_time": "5",
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
